{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Explainable Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\isabe\\\\Documents\\\\AI studies\\\\6.Semester\\\\Bachelor Thesis\\\\Paradime-NAMs\\\\Datasets\\\\heart.csv')\n",
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(df.columns) - 1 # minus target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataframe(df):\n",
    "    # Iterate over each column in the DataFrame\n",
    "    for column in df.columns:\n",
    "        if len(df[column].unique()) == 2 and df[column].dtype == object:\n",
    "            # Binary labels\n",
    "            unique_labels = df[column].unique()\n",
    "            mapping = {unique_labels[0]: 0, unique_labels[1]: 1}\n",
    "            df[column] = df[column].map(mapping)\n",
    "        elif df[column].dtype == object:\n",
    "            # Multiple labels (strings)\n",
    "            dummies = pd.get_dummies(df[column], prefix=column)\n",
    "            df = pd.concat([df, dummies], axis=1)\n",
    "            df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = preprocess_dataframe(df)\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting feature vector and target variable\n",
    "target_column = 'target' # should be specified by user \n",
    "X = df.drop([target_column], axis=1)\n",
    "y = df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13) (61, 13)\n"
     ]
    }
   ],
   "source": [
    "# Training and testing data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# check the shape of X_train and X_test\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the input ranges for each feature\n",
    "input_ranges = np.zeros((X.shape[1], 2))\n",
    "for i, col in enumerate(X.columns):\n",
    "    input_ranges[i, 0] = X[col].min()\n",
    "    input_ranges[i, 1] = X[col].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "class NAM(th.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=1, num_layers=1):\n",
    "        super(NAM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.submodules = th.nn.ModuleList()\n",
    "        print(input_dim)\n",
    "\n",
    "        # Create the submodules for each input feature\n",
    "        for i in range(input_dim):\n",
    "            submodule = th.nn.Sequential()\n",
    "            # Add layers to the submodule\n",
    "            for l in range(num_layers):\n",
    "                if l == 0:\n",
    "                    submodule.add_module(f\"linear_{l}\", th.nn.Linear(1, hidden_dim))\n",
    "                else:\n",
    "                    submodule.add_module(f\"linear_{l}\", th.nn.Linear(hidden_dim, hidden_dim))\n",
    "                submodule.add_module(f\"ELU_{l}\", th.nn.ELU())\n",
    "                submodule.add_module(f\"dropout_{l}\", th.nn.Dropout(0.5))\n",
    "\n",
    "            # Add the output layer\n",
    "            submodule.add_module(f\"linear_{num_layers}\", th.nn.Linear(hidden_dim, output_dim))\n",
    "            self.submodules.append(submodule)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = th.zeros(x.shape[0], self.output_dim)\n",
    "\n",
    "        # Apply each submodule to its corresponding input feature and sum the results\n",
    "        for i in range(self.input_dim):\n",
    "            output += self.submodules[i](x[:, i].unsqueeze(1))\n",
    "\n",
    "        # Apply sigmoid activation for binary classification\n",
    "        return th.sigmoid(output)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        # Initialize the weights of linear layers\n",
    "        if type(m) == th.nn.Linear:\n",
    "            th.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def get_feature_maps(self, resolution=100):\n",
    "        # Initialize the output\n",
    "        output = th.zeros(self.input_dim, resolution)\n",
    "\n",
    "        # For each input dimension, pass it through the corresponding submodule\n",
    "        for i in range(self.input_dim):\n",
    "            for j in range(resolution):\n",
    "                # Add each input dimension output to the overall output\n",
    "                output[i, j] = self.submodules[i](th.tensor([[j / resolution]]))\n",
    "\n",
    "        # Return the overall output as a NumPy array\n",
    "        return output.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "NAM(\n",
      "  (submodules): ModuleList(\n",
      "    (0-12): 13 x Sequential(\n",
      "      (linear_0): Linear(in_features=1, out_features=10, bias=True)\n",
      "      (ELU_0): ELU(alpha=1.0)\n",
      "      (dropout_0): Dropout(p=0.5, inplace=False)\n",
      "      (linear_1): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (ELU_1): ELU(alpha=1.0)\n",
      "      (dropout_1): Dropout(p=0.5, inplace=False)\n",
      "      (linear_2): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (ELU_2): ELU(alpha=1.0)\n",
      "      (dropout_2): Dropout(p=0.5, inplace=False)\n",
      "      (linear_3): Linear(in_features=10, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the Neural Additive Model\n",
    "# One input dimension for each feature\n",
    "# One output dimension for binary classification, using sigmoid activation on the output layer\n",
    "\n",
    "model = NAM(input_dim, hidden_dim=10, output_dim=1, num_layers=3)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "seed = 42\n",
    "th.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Initialize weights\n",
    "model.apply(model.init_weights)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Define the loss function (binary cross entropy for binary classification)\n",
    "loss_fn = th.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train function\n",
    "def train(model, X, y, optimizer, loss_fn):\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    X_tensor = th.tensor(X.to_numpy(), dtype=th.float32)  # Convert input data to tensor\n",
    "    y_tensor = th.tensor(y.to_numpy(), dtype=th.float32).unsqueeze(1)  # Convert target data to tensor\n",
    "    output = model(X_tensor)  # Forward pass to get the model output\n",
    "    loss = loss_fn(output, y_tensor)  # Compute the loss using the loss function\n",
    "    loss.backward()  # Compute the gradients through backpropagation\n",
    "    optimizer.step()  # Update the model weights using the optimizer\n",
    "    return loss.item()  # Return the loss value\n",
    "# Define the evaluation function\n",
    "def evaluate(model, X, y, loss_fn):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    X_tensor = th.tensor(X.to_numpy(), dtype=th.float32)  # Convert input data to tensor\n",
    "    y_tensor = th.tensor(y.to_numpy(), dtype=th.float32).unsqueeze(1)  # Convert target data to tensor\n",
    "    output = model(X_tensor)  # Forward pass to get the model output\n",
    "    loss = loss_fn(output, y_tensor)  # Compute the loss using the loss function\n",
    "    predictions = (output > 0.5).float()  # Threshold the output probabilities to binary predictions\n",
    "    correct = (predictions == y_tensor).sum().item()  # Count the number of correct predictions\n",
    "    accuracy = correct / y_tensor.shape[0]  # Compute the accuracy\n",
    "    return loss.item(), accuracy  # Return the loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 1.0273, test loss = 0.8726, test accuracy = 0.4590\n",
      "Epoch 2: train loss = 1.0675, test loss = 0.8248, test accuracy = 0.4754\n",
      "Epoch 3: train loss = 0.9585, test loss = 0.7865, test accuracy = 0.4754\n",
      "Epoch 4: train loss = 0.9115, test loss = 0.7567, test accuracy = 0.5410\n",
      "Epoch 5: train loss = 0.9313, test loss = 0.7349, test accuracy = 0.4590\n",
      "Epoch 6: train loss = 0.9627, test loss = 0.7192, test accuracy = 0.5574\n",
      "Epoch 7: train loss = 0.9740, test loss = 0.7085, test accuracy = 0.5574\n",
      "Epoch 8: train loss = 0.8977, test loss = 0.7012, test accuracy = 0.5574\n",
      "Epoch 9: train loss = 0.8935, test loss = 0.6959, test accuracy = 0.5246\n",
      "Epoch 10: train loss = 1.0353, test loss = 0.6916, test accuracy = 0.5082\n",
      "Epoch 11: train loss = 0.8622, test loss = 0.6873, test accuracy = 0.5082\n",
      "Epoch 12: train loss = 0.9035, test loss = 0.6828, test accuracy = 0.5082\n",
      "Epoch 13: train loss = 0.8589, test loss = 0.6776, test accuracy = 0.5246\n",
      "Epoch 14: train loss = 0.9162, test loss = 0.6722, test accuracy = 0.5410\n",
      "Epoch 15: train loss = 0.9005, test loss = 0.6666, test accuracy = 0.5738\n",
      "Epoch 16: train loss = 0.8447, test loss = 0.6607, test accuracy = 0.5738\n",
      "Epoch 17: train loss = 0.9435, test loss = 0.6548, test accuracy = 0.5902\n",
      "Epoch 18: train loss = 0.8161, test loss = 0.6491, test accuracy = 0.5738\n",
      "Epoch 19: train loss = 0.8601, test loss = 0.6439, test accuracy = 0.6066\n",
      "Epoch 20: train loss = 0.8461, test loss = 0.6393, test accuracy = 0.6066\n",
      "Epoch 21: train loss = 0.8577, test loss = 0.6354, test accuracy = 0.6230\n",
      "Epoch 22: train loss = 0.9320, test loss = 0.6319, test accuracy = 0.6393\n",
      "Epoch 23: train loss = 0.8284, test loss = 0.6289, test accuracy = 0.6557\n",
      "Epoch 24: train loss = 0.7469, test loss = 0.6264, test accuracy = 0.6885\n",
      "Epoch 25: train loss = 0.8532, test loss = 0.6242, test accuracy = 0.6721\n",
      "Epoch 26: train loss = 0.8250, test loss = 0.6220, test accuracy = 0.6721\n",
      "Epoch 27: train loss = 0.8176, test loss = 0.6202, test accuracy = 0.6885\n",
      "Epoch 28: train loss = 0.8074, test loss = 0.6179, test accuracy = 0.6721\n",
      "Epoch 29: train loss = 0.8354, test loss = 0.6149, test accuracy = 0.6721\n",
      "Epoch 30: train loss = 0.7795, test loss = 0.6111, test accuracy = 0.6721\n",
      "Epoch 31: train loss = 0.7618, test loss = 0.6074, test accuracy = 0.6885\n",
      "Epoch 32: train loss = 0.8574, test loss = 0.6035, test accuracy = 0.6885\n",
      "Epoch 33: train loss = 0.7508, test loss = 0.5992, test accuracy = 0.7049\n",
      "Epoch 34: train loss = 0.7267, test loss = 0.5951, test accuracy = 0.6885\n",
      "Epoch 35: train loss = 0.7426, test loss = 0.5905, test accuracy = 0.7049\n",
      "Epoch 36: train loss = 0.7817, test loss = 0.5858, test accuracy = 0.7049\n",
      "Epoch 37: train loss = 0.7043, test loss = 0.5813, test accuracy = 0.7049\n",
      "Epoch 38: train loss = 0.8061, test loss = 0.5766, test accuracy = 0.7541\n",
      "Epoch 39: train loss = 0.7227, test loss = 0.5722, test accuracy = 0.7541\n",
      "Epoch 40: train loss = 0.6758, test loss = 0.5678, test accuracy = 0.7705\n",
      "Epoch 41: train loss = 0.7976, test loss = 0.5637, test accuracy = 0.7541\n",
      "Epoch 42: train loss = 0.7169, test loss = 0.5597, test accuracy = 0.7541\n",
      "Epoch 43: train loss = 0.7830, test loss = 0.5561, test accuracy = 0.7541\n",
      "Epoch 44: train loss = 0.7314, test loss = 0.5527, test accuracy = 0.7541\n",
      "Epoch 45: train loss = 0.6421, test loss = 0.5494, test accuracy = 0.7705\n",
      "Epoch 46: train loss = 0.8132, test loss = 0.5465, test accuracy = 0.7705\n",
      "Epoch 47: train loss = 0.7153, test loss = 0.5439, test accuracy = 0.7705\n",
      "Epoch 48: train loss = 0.6599, test loss = 0.5413, test accuracy = 0.7705\n",
      "Epoch 49: train loss = 0.6527, test loss = 0.5389, test accuracy = 0.7705\n",
      "Epoch 50: train loss = 0.6435, test loss = 0.5367, test accuracy = 0.7705\n",
      "Epoch 51: train loss = 0.7189, test loss = 0.5345, test accuracy = 0.7705\n",
      "Epoch 52: train loss = 0.7010, test loss = 0.5326, test accuracy = 0.7705\n",
      "Epoch 53: train loss = 0.6563, test loss = 0.5307, test accuracy = 0.7705\n",
      "Epoch 54: train loss = 0.7233, test loss = 0.5289, test accuracy = 0.7705\n",
      "Epoch 55: train loss = 0.7224, test loss = 0.5271, test accuracy = 0.7541\n",
      "Epoch 56: train loss = 0.6775, test loss = 0.5253, test accuracy = 0.7541\n",
      "Epoch 57: train loss = 0.7004, test loss = 0.5236, test accuracy = 0.7541\n",
      "Epoch 58: train loss = 0.6530, test loss = 0.5219, test accuracy = 0.7541\n",
      "Epoch 59: train loss = 0.6552, test loss = 0.5200, test accuracy = 0.7541\n",
      "Epoch 60: train loss = 0.6357, test loss = 0.5182, test accuracy = 0.7541\n",
      "Epoch 61: train loss = 0.6514, test loss = 0.5163, test accuracy = 0.7541\n",
      "Epoch 62: train loss = 0.6991, test loss = 0.5143, test accuracy = 0.7705\n",
      "Epoch 63: train loss = 0.5950, test loss = 0.5124, test accuracy = 0.7705\n",
      "Epoch 64: train loss = 0.6645, test loss = 0.5105, test accuracy = 0.7705\n",
      "Epoch 65: train loss = 0.6685, test loss = 0.5086, test accuracy = 0.7705\n",
      "Epoch 66: train loss = 0.6178, test loss = 0.5067, test accuracy = 0.7705\n",
      "Epoch 67: train loss = 0.6161, test loss = 0.5048, test accuracy = 0.7705\n",
      "Epoch 68: train loss = 0.6408, test loss = 0.5028, test accuracy = 0.7705\n",
      "Epoch 69: train loss = 0.5978, test loss = 0.5008, test accuracy = 0.7705\n",
      "Epoch 70: train loss = 0.6302, test loss = 0.4990, test accuracy = 0.7705\n",
      "Epoch 71: train loss = 0.6231, test loss = 0.4972, test accuracy = 0.7705\n",
      "Epoch 72: train loss = 0.6894, test loss = 0.4957, test accuracy = 0.7705\n",
      "Epoch 73: train loss = 0.6143, test loss = 0.4943, test accuracy = 0.7705\n",
      "Epoch 74: train loss = 0.5617, test loss = 0.4928, test accuracy = 0.7705\n",
      "Epoch 75: train loss = 0.6815, test loss = 0.4914, test accuracy = 0.7705\n",
      "Epoch 76: train loss = 0.5891, test loss = 0.4900, test accuracy = 0.7705\n",
      "Epoch 77: train loss = 0.6488, test loss = 0.4887, test accuracy = 0.7705\n",
      "Epoch 78: train loss = 0.6419, test loss = 0.4874, test accuracy = 0.7705\n",
      "Epoch 79: train loss = 0.6001, test loss = 0.4862, test accuracy = 0.7705\n",
      "Epoch 80: train loss = 0.6353, test loss = 0.4851, test accuracy = 0.7705\n",
      "Epoch 81: train loss = 0.5698, test loss = 0.4839, test accuracy = 0.7705\n",
      "Epoch 82: train loss = 0.6518, test loss = 0.4828, test accuracy = 0.7705\n",
      "Epoch 83: train loss = 0.5892, test loss = 0.4817, test accuracy = 0.7705\n",
      "Epoch 84: train loss = 0.5924, test loss = 0.4807, test accuracy = 0.7705\n",
      "Epoch 85: train loss = 0.6157, test loss = 0.4797, test accuracy = 0.7705\n",
      "Epoch 86: train loss = 0.5401, test loss = 0.4787, test accuracy = 0.7705\n",
      "Epoch 87: train loss = 0.6222, test loss = 0.4776, test accuracy = 0.7705\n",
      "Epoch 88: train loss = 0.6090, test loss = 0.4768, test accuracy = 0.7705\n",
      "Epoch 89: train loss = 0.6405, test loss = 0.4760, test accuracy = 0.7541\n",
      "Epoch 90: train loss = 0.6337, test loss = 0.4752, test accuracy = 0.7541\n",
      "Epoch 91: train loss = 0.5509, test loss = 0.4745, test accuracy = 0.7541\n",
      "Epoch 92: train loss = 0.5527, test loss = 0.4739, test accuracy = 0.7541\n",
      "Epoch 93: train loss = 0.6513, test loss = 0.4733, test accuracy = 0.7541\n",
      "Epoch 94: train loss = 0.5428, test loss = 0.4727, test accuracy = 0.7541\n",
      "Epoch 95: train loss = 0.5471, test loss = 0.4720, test accuracy = 0.7541\n",
      "Epoch 96: train loss = 0.6004, test loss = 0.4714, test accuracy = 0.7541\n",
      "Epoch 97: train loss = 0.6273, test loss = 0.4710, test accuracy = 0.7541\n",
      "Epoch 98: train loss = 0.5517, test loss = 0.4704, test accuracy = 0.7541\n",
      "Epoch 99: train loss = 0.5872, test loss = 0.4700, test accuracy = 0.7541\n",
      "Epoch 100: train loss = 0.6341, test loss = 0.4693, test accuracy = 0.7541\n",
      "Epoch 101: train loss = 0.5220, test loss = 0.4687, test accuracy = 0.7541\n",
      "Epoch 102: train loss = 0.5019, test loss = 0.4682, test accuracy = 0.7541\n",
      "Epoch 103: train loss = 0.6091, test loss = 0.4672, test accuracy = 0.7541\n",
      "Epoch 104: train loss = 0.5108, test loss = 0.4659, test accuracy = 0.7541\n",
      "Epoch 105: train loss = 0.5746, test loss = 0.4649, test accuracy = 0.7541\n",
      "Epoch 106: train loss = 0.5387, test loss = 0.4639, test accuracy = 0.7541\n",
      "Epoch 107: train loss = 0.5566, test loss = 0.4630, test accuracy = 0.7541\n",
      "Epoch 108: train loss = 0.5150, test loss = 0.4624, test accuracy = 0.7541\n",
      "Epoch 109: train loss = 0.5626, test loss = 0.4618, test accuracy = 0.7541\n",
      "Epoch 110: train loss = 0.5322, test loss = 0.4612, test accuracy = 0.7541\n",
      "Epoch 111: train loss = 0.5459, test loss = 0.4606, test accuracy = 0.7541\n",
      "Epoch 112: train loss = 0.5981, test loss = 0.4600, test accuracy = 0.7541\n",
      "Epoch 113: train loss = 0.4860, test loss = 0.4592, test accuracy = 0.7541\n",
      "Epoch 114: train loss = 0.4796, test loss = 0.4583, test accuracy = 0.7541\n",
      "Epoch 115: train loss = 0.5922, test loss = 0.4574, test accuracy = 0.7541\n",
      "Epoch 116: train loss = 0.5217, test loss = 0.4564, test accuracy = 0.7705\n",
      "Epoch 117: train loss = 0.5462, test loss = 0.4557, test accuracy = 0.7705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118: train loss = 0.5419, test loss = 0.4551, test accuracy = 0.7705\n",
      "Epoch 119: train loss = 0.4849, test loss = 0.4544, test accuracy = 0.7705\n",
      "Epoch 120: train loss = 0.4923, test loss = 0.4539, test accuracy = 0.7705\n",
      "Epoch 121: train loss = 0.5855, test loss = 0.4534, test accuracy = 0.7705\n",
      "Epoch 122: train loss = 0.5893, test loss = 0.4530, test accuracy = 0.7705\n",
      "Epoch 123: train loss = 0.5574, test loss = 0.4526, test accuracy = 0.7705\n",
      "Epoch 124: train loss = 0.5468, test loss = 0.4523, test accuracy = 0.7705\n",
      "Epoch 125: train loss = 0.5279, test loss = 0.4520, test accuracy = 0.7705\n",
      "Epoch 126: train loss = 0.6039, test loss = 0.4517, test accuracy = 0.7705\n",
      "Epoch 127: train loss = 0.5610, test loss = 0.4514, test accuracy = 0.7705\n",
      "Epoch 128: train loss = 0.5465, test loss = 0.4512, test accuracy = 0.7705\n",
      "Epoch 129: train loss = 0.5907, test loss = 0.4510, test accuracy = 0.7705\n",
      "Epoch 130: train loss = 0.5497, test loss = 0.4510, test accuracy = 0.7705\n",
      "Epoch 131: train loss = 0.5315, test loss = 0.4508, test accuracy = 0.7541\n",
      "Epoch 132: train loss = 0.5487, test loss = 0.4508, test accuracy = 0.7541\n",
      "Epoch 133: train loss = 0.5539, test loss = 0.4507, test accuracy = 0.7541\n",
      "Epoch 134: train loss = 0.5353, test loss = 0.4506, test accuracy = 0.7541\n",
      "Epoch 135: train loss = 0.5303, test loss = 0.4506, test accuracy = 0.7541\n",
      "Epoch 136: train loss = 0.4932, test loss = 0.4506, test accuracy = 0.7541\n",
      "Epoch 137: train loss = 0.5264, test loss = 0.4503, test accuracy = 0.7541\n",
      "Epoch 138: train loss = 0.5480, test loss = 0.4499, test accuracy = 0.7541\n",
      "Epoch 139: train loss = 0.6141, test loss = 0.4495, test accuracy = 0.7541\n",
      "Epoch 140: train loss = 0.5760, test loss = 0.4492, test accuracy = 0.7541\n",
      "Epoch 141: train loss = 0.5017, test loss = 0.4490, test accuracy = 0.7541\n",
      "Epoch 142: train loss = 0.5101, test loss = 0.4484, test accuracy = 0.7541\n",
      "Epoch 143: train loss = 0.5245, test loss = 0.4478, test accuracy = 0.7541\n",
      "Epoch 144: train loss = 0.5415, test loss = 0.4472, test accuracy = 0.7541\n",
      "Epoch 145: train loss = 0.4971, test loss = 0.4466, test accuracy = 0.7541\n",
      "Epoch 146: train loss = 0.4790, test loss = 0.4458, test accuracy = 0.7541\n",
      "Epoch 147: train loss = 0.5776, test loss = 0.4451, test accuracy = 0.7705\n",
      "Epoch 148: train loss = 0.4860, test loss = 0.4445, test accuracy = 0.7705\n",
      "Epoch 149: train loss = 0.6127, test loss = 0.4438, test accuracy = 0.7705\n",
      "Epoch 150: train loss = 0.5511, test loss = 0.4431, test accuracy = 0.7705\n",
      "Epoch 151: train loss = 0.5365, test loss = 0.4426, test accuracy = 0.7705\n",
      "Epoch 152: train loss = 0.5499, test loss = 0.4419, test accuracy = 0.7705\n",
      "Epoch 153: train loss = 0.5629, test loss = 0.4411, test accuracy = 0.7705\n",
      "Epoch 154: train loss = 0.4968, test loss = 0.4403, test accuracy = 0.7705\n",
      "Epoch 155: train loss = 0.5328, test loss = 0.4394, test accuracy = 0.7705\n",
      "Epoch 156: train loss = 0.5412, test loss = 0.4387, test accuracy = 0.7705\n",
      "Epoch 157: train loss = 0.4964, test loss = 0.4380, test accuracy = 0.7705\n",
      "Epoch 158: train loss = 0.4941, test loss = 0.4373, test accuracy = 0.7705\n",
      "Epoch 159: train loss = 0.4607, test loss = 0.4366, test accuracy = 0.7705\n",
      "Epoch 160: train loss = 0.5863, test loss = 0.4359, test accuracy = 0.7705\n",
      "Epoch 161: train loss = 0.4966, test loss = 0.4353, test accuracy = 0.7705\n",
      "Epoch 162: train loss = 0.5666, test loss = 0.4348, test accuracy = 0.7705\n",
      "Epoch 163: train loss = 0.5736, test loss = 0.4344, test accuracy = 0.7705\n",
      "Epoch 164: train loss = 0.5566, test loss = 0.4340, test accuracy = 0.7705\n",
      "Epoch 165: train loss = 0.5740, test loss = 0.4336, test accuracy = 0.7705\n",
      "Epoch 166: train loss = 0.5360, test loss = 0.4333, test accuracy = 0.7705\n",
      "Epoch 167: train loss = 0.4732, test loss = 0.4331, test accuracy = 0.7705\n",
      "Epoch 168: train loss = 0.4511, test loss = 0.4330, test accuracy = 0.7705\n",
      "Epoch 169: train loss = 0.5815, test loss = 0.4329, test accuracy = 0.7705\n",
      "Epoch 170: train loss = 0.4938, test loss = 0.4329, test accuracy = 0.7705\n",
      "Epoch 171: train loss = 0.4875, test loss = 0.4328, test accuracy = 0.7705\n",
      "Epoch 172: train loss = 0.5068, test loss = 0.4328, test accuracy = 0.7705\n",
      "Epoch 173: train loss = 0.4984, test loss = 0.4328, test accuracy = 0.7705\n",
      "Epoch 174: train loss = 0.4772, test loss = 0.4327, test accuracy = 0.7705\n",
      "Epoch 175: train loss = 0.4911, test loss = 0.4327, test accuracy = 0.7705\n",
      "Epoch 176: train loss = 0.4825, test loss = 0.4325, test accuracy = 0.7705\n",
      "Epoch 177: train loss = 0.4630, test loss = 0.4323, test accuracy = 0.7705\n",
      "Epoch 178: train loss = 0.4893, test loss = 0.4322, test accuracy = 0.7705\n",
      "Epoch 179: train loss = 0.5262, test loss = 0.4322, test accuracy = 0.7705\n",
      "Epoch 180: train loss = 0.5379, test loss = 0.4322, test accuracy = 0.7705\n",
      "Epoch 181: train loss = 0.5750, test loss = 0.4322, test accuracy = 0.7705\n",
      "Epoch 182: train loss = 0.4961, test loss = 0.4323, test accuracy = 0.7705\n",
      "Epoch 183: train loss = 0.4932, test loss = 0.4324, test accuracy = 0.7705\n",
      "Epoch 184: train loss = 0.5069, test loss = 0.4327, test accuracy = 0.7705\n",
      "Epoch 185: train loss = 0.5043, test loss = 0.4329, test accuracy = 0.7705\n",
      "Epoch 186: train loss = 0.5396, test loss = 0.4329, test accuracy = 0.7705\n",
      "Epoch 187: train loss = 0.5122, test loss = 0.4329, test accuracy = 0.7705\n",
      "Epoch 188: train loss = 0.5246, test loss = 0.4328, test accuracy = 0.7705\n",
      "Epoch 189: train loss = 0.4817, test loss = 0.4325, test accuracy = 0.7705\n",
      "Epoch 190: train loss = 0.4609, test loss = 0.4322, test accuracy = 0.7705\n",
      "Epoch 191: train loss = 0.5131, test loss = 0.4318, test accuracy = 0.7705\n",
      "Epoch 192: train loss = 0.5102, test loss = 0.4315, test accuracy = 0.7705\n",
      "Epoch 193: train loss = 0.4609, test loss = 0.4310, test accuracy = 0.7705\n",
      "Epoch 194: train loss = 0.5220, test loss = 0.4305, test accuracy = 0.7705\n",
      "Epoch 195: train loss = 0.4387, test loss = 0.4302, test accuracy = 0.7705\n",
      "Epoch 196: train loss = 0.4741, test loss = 0.4300, test accuracy = 0.7705\n",
      "Epoch 197: train loss = 0.4780, test loss = 0.4298, test accuracy = 0.7705\n",
      "Epoch 198: train loss = 0.5207, test loss = 0.4297, test accuracy = 0.7705\n",
      "Epoch 199: train loss = 0.4877, test loss = 0.4297, test accuracy = 0.7705\n",
      "Epoch 200: train loss = 0.5333, test loss = 0.4296, test accuracy = 0.7705\n",
      "Epoch 201: train loss = 0.4641, test loss = 0.4295, test accuracy = 0.7705\n",
      "Epoch 202: train loss = 0.4653, test loss = 0.4295, test accuracy = 0.7705\n",
      "Epoch 203: train loss = 0.4591, test loss = 0.4293, test accuracy = 0.7705\n",
      "Epoch 204: train loss = 0.4363, test loss = 0.4291, test accuracy = 0.7705\n",
      "Epoch 205: train loss = 0.4987, test loss = 0.4289, test accuracy = 0.7705\n",
      "Epoch 206: train loss = 0.4324, test loss = 0.4287, test accuracy = 0.7705\n",
      "Epoch 207: train loss = 0.5490, test loss = 0.4286, test accuracy = 0.7705\n",
      "Epoch 208: train loss = 0.4773, test loss = 0.4284, test accuracy = 0.7705\n",
      "Epoch 209: train loss = 0.4711, test loss = 0.4282, test accuracy = 0.7705\n",
      "Epoch 210: train loss = 0.4914, test loss = 0.4278, test accuracy = 0.7705\n",
      "Epoch 211: train loss = 0.4664, test loss = 0.4275, test accuracy = 0.7705\n",
      "Epoch 212: train loss = 0.4886, test loss = 0.4273, test accuracy = 0.7705\n",
      "Epoch 213: train loss = 0.4938, test loss = 0.4272, test accuracy = 0.7705\n",
      "Epoch 214: train loss = 0.5276, test loss = 0.4273, test accuracy = 0.7705\n",
      "Epoch 215: train loss = 0.4887, test loss = 0.4274, test accuracy = 0.7705\n",
      "Epoch 216: train loss = 0.5290, test loss = 0.4274, test accuracy = 0.7705\n",
      "Epoch 217: train loss = 0.5422, test loss = 0.4274, test accuracy = 0.7705\n",
      "Epoch 218: train loss = 0.4827, test loss = 0.4274, test accuracy = 0.7705\n",
      "Epoch 219: train loss = 0.5137, test loss = 0.4272, test accuracy = 0.7705\n",
      "Epoch 220: train loss = 0.5310, test loss = 0.4271, test accuracy = 0.7705\n",
      "Epoch 221: train loss = 0.4842, test loss = 0.4271, test accuracy = 0.7705\n",
      "Epoch 222: train loss = 0.4822, test loss = 0.4269, test accuracy = 0.7705\n",
      "Epoch 223: train loss = 0.4845, test loss = 0.4266, test accuracy = 0.7705\n",
      "Epoch 224: train loss = 0.5408, test loss = 0.4265, test accuracy = 0.7705\n",
      "Epoch 225: train loss = 0.4583, test loss = 0.4263, test accuracy = 0.7705\n",
      "Epoch 226: train loss = 0.4483, test loss = 0.4262, test accuracy = 0.7705\n",
      "Epoch 227: train loss = 0.4471, test loss = 0.4259, test accuracy = 0.7705\n",
      "Epoch 228: train loss = 0.5095, test loss = 0.4257, test accuracy = 0.7705\n",
      "Epoch 229: train loss = 0.5209, test loss = 0.4254, test accuracy = 0.7705\n",
      "Epoch 230: train loss = 0.4816, test loss = 0.4253, test accuracy = 0.7705\n",
      "Epoch 231: train loss = 0.4502, test loss = 0.4250, test accuracy = 0.7705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232: train loss = 0.4933, test loss = 0.4248, test accuracy = 0.7705\n",
      "Epoch 233: train loss = 0.5018, test loss = 0.4246, test accuracy = 0.7705\n",
      "Epoch 234: train loss = 0.4598, test loss = 0.4243, test accuracy = 0.7705\n",
      "Epoch 235: train loss = 0.4514, test loss = 0.4241, test accuracy = 0.7705\n",
      "Epoch 236: train loss = 0.5368, test loss = 0.4239, test accuracy = 0.7705\n",
      "Epoch 237: train loss = 0.4776, test loss = 0.4238, test accuracy = 0.7705\n",
      "Epoch 238: train loss = 0.5165, test loss = 0.4237, test accuracy = 0.7705\n",
      "Epoch 239: train loss = 0.5199, test loss = 0.4235, test accuracy = 0.7705\n",
      "Epoch 240: train loss = 0.4230, test loss = 0.4235, test accuracy = 0.7705\n",
      "Epoch 241: train loss = 0.4169, test loss = 0.4234, test accuracy = 0.7705\n",
      "Epoch 242: train loss = 0.4365, test loss = 0.4232, test accuracy = 0.7705\n",
      "Epoch 243: train loss = 0.4035, test loss = 0.4231, test accuracy = 0.7705\n",
      "Epoch 244: train loss = 0.4808, test loss = 0.4229, test accuracy = 0.7705\n",
      "Epoch 245: train loss = 0.4478, test loss = 0.4228, test accuracy = 0.7705\n",
      "Epoch 246: train loss = 0.4742, test loss = 0.4227, test accuracy = 0.7705\n",
      "Epoch 247: train loss = 0.4801, test loss = 0.4226, test accuracy = 0.7705\n",
      "Epoch 248: train loss = 0.4471, test loss = 0.4226, test accuracy = 0.7705\n",
      "Epoch 249: train loss = 0.4541, test loss = 0.4226, test accuracy = 0.7705\n",
      "Epoch 250: train loss = 0.4813, test loss = 0.4227, test accuracy = 0.7705\n",
      "Epoch 251: train loss = 0.5189, test loss = 0.4229, test accuracy = 0.7705\n",
      "Epoch 252: train loss = 0.3851, test loss = 0.4231, test accuracy = 0.7705\n",
      "Epoch 253: train loss = 0.4934, test loss = 0.4234, test accuracy = 0.7705\n",
      "Epoch 254: train loss = 0.4870, test loss = 0.4238, test accuracy = 0.7705\n",
      "Epoch 255: train loss = 0.4702, test loss = 0.4240, test accuracy = 0.7705\n",
      "Epoch 256: train loss = 0.4777, test loss = 0.4242, test accuracy = 0.7705\n",
      "Epoch 257: train loss = 0.5100, test loss = 0.4242, test accuracy = 0.7705\n",
      "Epoch 258: train loss = 0.5126, test loss = 0.4242, test accuracy = 0.7705\n",
      "Epoch 259: train loss = 0.4731, test loss = 0.4241, test accuracy = 0.7705\n",
      "Epoch 260: train loss = 0.4756, test loss = 0.4242, test accuracy = 0.7705\n",
      "Epoch 261: train loss = 0.4470, test loss = 0.4241, test accuracy = 0.7705\n",
      "Epoch 262: train loss = 0.4606, test loss = 0.4241, test accuracy = 0.7705\n",
      "Epoch 263: train loss = 0.5431, test loss = 0.4242, test accuracy = 0.7705\n",
      "Epoch 264: train loss = 0.5249, test loss = 0.4243, test accuracy = 0.7705\n",
      "Epoch 265: train loss = 0.4654, test loss = 0.4244, test accuracy = 0.7705\n",
      "Epoch 266: train loss = 0.4632, test loss = 0.4246, test accuracy = 0.7705\n",
      "Epoch 267: train loss = 0.4796, test loss = 0.4246, test accuracy = 0.7705\n",
      "Epoch 268: train loss = 0.4830, test loss = 0.4246, test accuracy = 0.7705\n",
      "Epoch 269: train loss = 0.4919, test loss = 0.4246, test accuracy = 0.7705\n",
      "Epoch 270: train loss = 0.4862, test loss = 0.4247, test accuracy = 0.7705\n",
      "Epoch 271: train loss = 0.5113, test loss = 0.4248, test accuracy = 0.7705\n",
      "Epoch 272: train loss = 0.4743, test loss = 0.4249, test accuracy = 0.7705\n",
      "Epoch 273: train loss = 0.4722, test loss = 0.4250, test accuracy = 0.7705\n",
      "Epoch 274: train loss = 0.4822, test loss = 0.4251, test accuracy = 0.7705\n",
      "Epoch 275: train loss = 0.5004, test loss = 0.4252, test accuracy = 0.7705\n",
      "Epoch 276: train loss = 0.4289, test loss = 0.4253, test accuracy = 0.7705\n",
      "Epoch 277: train loss = 0.4517, test loss = 0.4254, test accuracy = 0.7705\n",
      "Epoch 278: train loss = 0.4971, test loss = 0.4254, test accuracy = 0.7705\n",
      "Epoch 279: train loss = 0.4969, test loss = 0.4254, test accuracy = 0.7705\n",
      "Epoch 280: train loss = 0.4695, test loss = 0.4255, test accuracy = 0.7705\n",
      "Epoch 281: train loss = 0.4525, test loss = 0.4255, test accuracy = 0.7705\n",
      "Epoch 282: train loss = 0.4648, test loss = 0.4254, test accuracy = 0.7705\n",
      "Epoch 283: train loss = 0.4680, test loss = 0.4251, test accuracy = 0.7705\n",
      "Epoch 284: train loss = 0.5120, test loss = 0.4248, test accuracy = 0.7705\n",
      "Epoch 285: train loss = 0.5024, test loss = 0.4244, test accuracy = 0.7705\n",
      "Epoch 286: train loss = 0.4186, test loss = 0.4239, test accuracy = 0.7705\n",
      "Epoch 287: train loss = 0.5561, test loss = 0.4235, test accuracy = 0.7705\n",
      "Epoch 288: train loss = 0.4840, test loss = 0.4231, test accuracy = 0.7705\n",
      "Epoch 289: train loss = 0.4367, test loss = 0.4226, test accuracy = 0.7705\n",
      "Epoch 290: train loss = 0.4565, test loss = 0.4223, test accuracy = 0.7705\n",
      "Epoch 291: train loss = 0.5217, test loss = 0.4222, test accuracy = 0.7705\n",
      "Epoch 292: train loss = 0.4505, test loss = 0.4220, test accuracy = 0.7705\n",
      "Epoch 293: train loss = 0.4467, test loss = 0.4217, test accuracy = 0.7705\n",
      "Epoch 294: train loss = 0.4503, test loss = 0.4215, test accuracy = 0.7705\n",
      "Epoch 295: train loss = 0.4775, test loss = 0.4215, test accuracy = 0.7705\n",
      "Epoch 296: train loss = 0.4892, test loss = 0.4213, test accuracy = 0.7705\n",
      "Epoch 297: train loss = 0.3970, test loss = 0.4212, test accuracy = 0.7705\n",
      "Epoch 298: train loss = 0.4333, test loss = 0.4209, test accuracy = 0.7705\n",
      "Epoch 299: train loss = 0.5012, test loss = 0.4206, test accuracy = 0.7705\n",
      "Epoch 300: train loss = 0.4725, test loss = 0.4203, test accuracy = 0.7705\n",
      "Epoch 301: train loss = 0.4552, test loss = 0.4200, test accuracy = 0.7705\n",
      "Epoch 302: train loss = 0.4450, test loss = 0.4198, test accuracy = 0.7705\n",
      "Epoch 303: train loss = 0.4352, test loss = 0.4197, test accuracy = 0.7705\n",
      "Epoch 304: train loss = 0.4793, test loss = 0.4196, test accuracy = 0.7705\n",
      "Epoch 305: train loss = 0.5243, test loss = 0.4197, test accuracy = 0.7705\n",
      "Epoch 306: train loss = 0.4451, test loss = 0.4198, test accuracy = 0.7705\n",
      "Epoch 307: train loss = 0.4824, test loss = 0.4200, test accuracy = 0.7705\n",
      "Epoch 308: train loss = 0.4501, test loss = 0.4202, test accuracy = 0.7705\n",
      "Epoch 309: train loss = 0.4599, test loss = 0.4204, test accuracy = 0.7705\n",
      "Epoch 310: train loss = 0.4763, test loss = 0.4204, test accuracy = 0.7705\n",
      "Epoch 311: train loss = 0.4392, test loss = 0.4206, test accuracy = 0.7705\n",
      "Epoch 312: train loss = 0.4213, test loss = 0.4207, test accuracy = 0.7705\n",
      "Epoch 313: train loss = 0.5151, test loss = 0.4204, test accuracy = 0.7705\n",
      "Epoch 314: train loss = 0.4994, test loss = 0.4200, test accuracy = 0.7705\n",
      "Epoch 315: train loss = 0.4756, test loss = 0.4196, test accuracy = 0.7705\n",
      "Epoch 316: train loss = 0.4986, test loss = 0.4193, test accuracy = 0.7705\n",
      "Epoch 317: train loss = 0.4208, test loss = 0.4192, test accuracy = 0.7705\n",
      "Epoch 318: train loss = 0.4918, test loss = 0.4191, test accuracy = 0.7705\n",
      "Epoch 319: train loss = 0.4678, test loss = 0.4188, test accuracy = 0.7705\n",
      "Epoch 320: train loss = 0.4520, test loss = 0.4186, test accuracy = 0.7705\n",
      "Epoch 321: train loss = 0.4403, test loss = 0.4185, test accuracy = 0.7705\n",
      "Epoch 322: train loss = 0.4615, test loss = 0.4183, test accuracy = 0.7705\n",
      "Epoch 323: train loss = 0.4638, test loss = 0.4181, test accuracy = 0.7705\n",
      "Epoch 324: train loss = 0.4644, test loss = 0.4181, test accuracy = 0.7705\n",
      "Epoch 325: train loss = 0.5009, test loss = 0.4180, test accuracy = 0.7705\n",
      "Epoch 326: train loss = 0.4899, test loss = 0.4180, test accuracy = 0.7705\n",
      "Epoch 327: train loss = 0.4520, test loss = 0.4179, test accuracy = 0.7705\n",
      "Epoch 328: train loss = 0.4172, test loss = 0.4179, test accuracy = 0.7705\n",
      "Epoch 329: train loss = 0.4411, test loss = 0.4180, test accuracy = 0.7705\n",
      "Epoch 330: train loss = 0.5014, test loss = 0.4181, test accuracy = 0.7705\n",
      "Epoch 331: train loss = 0.5119, test loss = 0.4184, test accuracy = 0.7705\n",
      "Epoch 332: train loss = 0.4820, test loss = 0.4190, test accuracy = 0.7705\n",
      "Epoch 333: train loss = 0.4677, test loss = 0.4196, test accuracy = 0.7705\n",
      "Epoch 334: train loss = 0.5107, test loss = 0.4202, test accuracy = 0.7705\n",
      "Epoch 335: train loss = 0.4690, test loss = 0.4208, test accuracy = 0.7705\n",
      "Epoch 336: train loss = 0.4285, test loss = 0.4215, test accuracy = 0.7541\n",
      "Epoch 337: train loss = 0.4954, test loss = 0.4220, test accuracy = 0.7541\n",
      "Epoch 338: train loss = 0.4260, test loss = 0.4225, test accuracy = 0.7541\n",
      "Epoch 339: train loss = 0.4325, test loss = 0.4228, test accuracy = 0.7541\n",
      "Epoch 340: train loss = 0.4660, test loss = 0.4229, test accuracy = 0.7541\n",
      "Epoch 341: train loss = 0.4611, test loss = 0.4228, test accuracy = 0.7541\n",
      "Epoch 342: train loss = 0.4782, test loss = 0.4225, test accuracy = 0.7541\n",
      "Epoch 343: train loss = 0.4467, test loss = 0.4223, test accuracy = 0.7541\n",
      "Epoch 344: train loss = 0.4919, test loss = 0.4221, test accuracy = 0.7705\n",
      "Epoch 345: train loss = 0.4251, test loss = 0.4220, test accuracy = 0.7705\n",
      "Epoch 346: train loss = 0.5008, test loss = 0.4217, test accuracy = 0.7705\n",
      "Epoch 347: train loss = 0.4639, test loss = 0.4212, test accuracy = 0.7705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348: train loss = 0.4462, test loss = 0.4205, test accuracy = 0.7705\n",
      "Epoch 349: train loss = 0.4396, test loss = 0.4200, test accuracy = 0.7705\n",
      "Epoch 350: train loss = 0.4465, test loss = 0.4195, test accuracy = 0.7705\n",
      "Epoch 351: train loss = 0.4522, test loss = 0.4192, test accuracy = 0.7705\n",
      "Epoch 352: train loss = 0.4839, test loss = 0.4189, test accuracy = 0.7705\n",
      "Epoch 353: train loss = 0.4425, test loss = 0.4186, test accuracy = 0.7705\n",
      "Epoch 354: train loss = 0.4213, test loss = 0.4183, test accuracy = 0.7705\n",
      "Epoch 355: train loss = 0.4519, test loss = 0.4179, test accuracy = 0.7705\n",
      "Epoch 356: train loss = 0.4303, test loss = 0.4175, test accuracy = 0.7705\n",
      "Epoch 357: train loss = 0.4596, test loss = 0.4171, test accuracy = 0.7705\n",
      "Epoch 358: train loss = 0.4828, test loss = 0.4169, test accuracy = 0.7705\n",
      "Epoch 359: train loss = 0.4055, test loss = 0.4166, test accuracy = 0.7705\n",
      "Epoch 360: train loss = 0.5173, test loss = 0.4165, test accuracy = 0.7705\n",
      "Epoch 361: train loss = 0.4210, test loss = 0.4163, test accuracy = 0.7705\n",
      "Epoch 362: train loss = 0.4576, test loss = 0.4162, test accuracy = 0.7705\n",
      "Epoch 363: train loss = 0.4580, test loss = 0.4161, test accuracy = 0.7705\n",
      "Epoch 364: train loss = 0.5171, test loss = 0.4160, test accuracy = 0.7705\n",
      "Epoch 365: train loss = 0.4205, test loss = 0.4159, test accuracy = 0.7705\n",
      "Epoch 366: train loss = 0.4404, test loss = 0.4158, test accuracy = 0.7705\n",
      "Epoch 367: train loss = 0.4779, test loss = 0.4154, test accuracy = 0.7705\n",
      "Epoch 368: train loss = 0.4463, test loss = 0.4151, test accuracy = 0.7705\n",
      "Epoch 369: train loss = 0.4764, test loss = 0.4148, test accuracy = 0.7705\n",
      "Epoch 370: train loss = 0.4184, test loss = 0.4146, test accuracy = 0.7705\n",
      "Epoch 371: train loss = 0.4716, test loss = 0.4144, test accuracy = 0.7705\n",
      "Epoch 372: train loss = 0.4598, test loss = 0.4142, test accuracy = 0.7705\n",
      "Epoch 373: train loss = 0.4741, test loss = 0.4141, test accuracy = 0.7705\n",
      "Epoch 374: train loss = 0.4863, test loss = 0.4140, test accuracy = 0.7705\n",
      "Epoch 375: train loss = 0.4458, test loss = 0.4138, test accuracy = 0.7705\n",
      "Epoch 376: train loss = 0.4463, test loss = 0.4137, test accuracy = 0.7705\n",
      "Epoch 377: train loss = 0.4597, test loss = 0.4134, test accuracy = 0.7705\n",
      "Epoch 378: train loss = 0.4657, test loss = 0.4132, test accuracy = 0.7705\n",
      "Epoch 379: train loss = 0.4606, test loss = 0.4128, test accuracy = 0.7705\n",
      "Epoch 380: train loss = 0.4434, test loss = 0.4125, test accuracy = 0.7705\n",
      "Epoch 381: train loss = 0.4608, test loss = 0.4122, test accuracy = 0.7705\n",
      "Epoch 382: train loss = 0.4596, test loss = 0.4119, test accuracy = 0.7705\n",
      "Epoch 383: train loss = 0.4962, test loss = 0.4117, test accuracy = 0.7705\n",
      "Epoch 384: train loss = 0.4681, test loss = 0.4115, test accuracy = 0.7705\n",
      "Epoch 385: train loss = 0.4935, test loss = 0.4113, test accuracy = 0.7705\n",
      "Epoch 386: train loss = 0.4376, test loss = 0.4111, test accuracy = 0.7705\n",
      "Epoch 387: train loss = 0.4362, test loss = 0.4111, test accuracy = 0.7705\n",
      "Epoch 388: train loss = 0.4761, test loss = 0.4109, test accuracy = 0.7705\n",
      "Epoch 389: train loss = 0.4685, test loss = 0.4108, test accuracy = 0.7705\n",
      "Epoch 390: train loss = 0.4653, test loss = 0.4106, test accuracy = 0.7705\n",
      "Epoch 391: train loss = 0.4887, test loss = 0.4105, test accuracy = 0.7705\n",
      "Epoch 392: train loss = 0.4598, test loss = 0.4104, test accuracy = 0.7705\n",
      "Epoch 393: train loss = 0.4382, test loss = 0.4102, test accuracy = 0.7705\n",
      "Epoch 394: train loss = 0.4613, test loss = 0.4101, test accuracy = 0.7705\n",
      "Epoch 395: train loss = 0.4763, test loss = 0.4100, test accuracy = 0.7705\n",
      "Epoch 396: train loss = 0.4559, test loss = 0.4099, test accuracy = 0.7705\n",
      "Epoch 397: train loss = 0.4610, test loss = 0.4096, test accuracy = 0.7705\n",
      "Epoch 398: train loss = 0.4374, test loss = 0.4095, test accuracy = 0.7705\n",
      "Epoch 399: train loss = 0.4807, test loss = 0.4094, test accuracy = 0.7705\n",
      "Epoch 400: train loss = 0.4319, test loss = 0.4092, test accuracy = 0.7705\n",
      "Epoch 401: train loss = 0.4145, test loss = 0.4091, test accuracy = 0.7705\n",
      "Epoch 402: train loss = 0.4897, test loss = 0.4089, test accuracy = 0.7705\n",
      "Epoch 403: train loss = 0.4068, test loss = 0.4087, test accuracy = 0.7705\n",
      "Epoch 404: train loss = 0.4498, test loss = 0.4086, test accuracy = 0.7705\n",
      "Epoch 405: train loss = 0.4854, test loss = 0.4085, test accuracy = 0.7705\n",
      "Epoch 406: train loss = 0.4563, test loss = 0.4085, test accuracy = 0.7705\n",
      "Epoch 407: train loss = 0.4354, test loss = 0.4084, test accuracy = 0.7705\n",
      "Epoch 408: train loss = 0.4311, test loss = 0.4085, test accuracy = 0.7705\n",
      "Epoch 409: train loss = 0.4416, test loss = 0.4086, test accuracy = 0.7705\n",
      "Epoch 410: train loss = 0.4355, test loss = 0.4087, test accuracy = 0.7705\n",
      "Epoch 411: train loss = 0.4849, test loss = 0.4088, test accuracy = 0.7705\n",
      "Epoch 412: train loss = 0.3932, test loss = 0.4088, test accuracy = 0.7705\n",
      "Epoch 413: train loss = 0.4422, test loss = 0.4087, test accuracy = 0.7705\n",
      "Epoch 414: train loss = 0.4938, test loss = 0.4083, test accuracy = 0.7705\n",
      "Epoch 415: train loss = 0.4464, test loss = 0.4078, test accuracy = 0.7705\n",
      "Epoch 416: train loss = 0.4580, test loss = 0.4072, test accuracy = 0.7705\n",
      "Epoch 417: train loss = 0.4180, test loss = 0.4067, test accuracy = 0.7705\n",
      "Epoch 418: train loss = 0.4526, test loss = 0.4062, test accuracy = 0.7705\n",
      "Epoch 419: train loss = 0.4741, test loss = 0.4057, test accuracy = 0.7705\n",
      "Epoch 420: train loss = 0.4374, test loss = 0.4053, test accuracy = 0.7705\n",
      "Epoch 421: train loss = 0.4523, test loss = 0.4051, test accuracy = 0.7705\n",
      "Epoch 422: train loss = 0.4489, test loss = 0.4052, test accuracy = 0.7705\n",
      "Epoch 423: train loss = 0.4245, test loss = 0.4054, test accuracy = 0.7705\n",
      "Epoch 424: train loss = 0.4454, test loss = 0.4058, test accuracy = 0.7705\n",
      "Epoch 425: train loss = 0.5025, test loss = 0.4062, test accuracy = 0.7705\n",
      "Epoch 426: train loss = 0.4468, test loss = 0.4065, test accuracy = 0.7705\n",
      "Epoch 427: train loss = 0.4914, test loss = 0.4068, test accuracy = 0.7705\n",
      "Epoch 428: train loss = 0.4042, test loss = 0.4071, test accuracy = 0.7705\n",
      "Epoch 429: train loss = 0.4425, test loss = 0.4075, test accuracy = 0.7705\n",
      "Epoch 430: train loss = 0.4423, test loss = 0.4077, test accuracy = 0.7705\n",
      "Epoch 431: train loss = 0.4413, test loss = 0.4079, test accuracy = 0.7705\n",
      "Epoch 432: train loss = 0.4538, test loss = 0.4081, test accuracy = 0.7705\n",
      "Epoch 433: train loss = 0.4121, test loss = 0.4085, test accuracy = 0.7705\n",
      "Epoch 434: train loss = 0.4299, test loss = 0.4086, test accuracy = 0.7705\n",
      "Epoch 435: train loss = 0.4506, test loss = 0.4086, test accuracy = 0.7705\n",
      "Epoch 436: train loss = 0.4325, test loss = 0.4086, test accuracy = 0.7705\n",
      "Epoch 437: train loss = 0.4151, test loss = 0.4084, test accuracy = 0.7705\n",
      "Epoch 438: train loss = 0.4211, test loss = 0.4083, test accuracy = 0.7705\n",
      "Epoch 439: train loss = 0.4402, test loss = 0.4082, test accuracy = 0.7705\n",
      "Epoch 440: train loss = 0.4290, test loss = 0.4080, test accuracy = 0.7705\n",
      "Epoch 441: train loss = 0.4487, test loss = 0.4077, test accuracy = 0.7705\n",
      "Epoch 442: train loss = 0.3965, test loss = 0.4074, test accuracy = 0.7705\n",
      "Epoch 443: train loss = 0.4312, test loss = 0.4073, test accuracy = 0.7705\n",
      "Epoch 444: train loss = 0.4551, test loss = 0.4071, test accuracy = 0.7705\n",
      "Epoch 445: train loss = 0.4149, test loss = 0.4070, test accuracy = 0.7705\n",
      "Epoch 446: train loss = 0.4432, test loss = 0.4069, test accuracy = 0.7705\n",
      "Epoch 447: train loss = 0.4416, test loss = 0.4067, test accuracy = 0.7705\n",
      "Epoch 448: train loss = 0.3793, test loss = 0.4066, test accuracy = 0.7705\n",
      "Epoch 449: train loss = 0.4151, test loss = 0.4064, test accuracy = 0.7705\n",
      "Epoch 450: train loss = 0.4645, test loss = 0.4062, test accuracy = 0.7705\n",
      "Epoch 451: train loss = 0.4580, test loss = 0.4058, test accuracy = 0.7705\n",
      "Epoch 452: train loss = 0.4467, test loss = 0.4056, test accuracy = 0.7705\n",
      "Epoch 453: train loss = 0.4503, test loss = 0.4055, test accuracy = 0.7705\n",
      "Epoch 454: train loss = 0.4432, test loss = 0.4055, test accuracy = 0.7705\n",
      "Epoch 455: train loss = 0.4398, test loss = 0.4054, test accuracy = 0.7705\n",
      "Epoch 456: train loss = 0.4194, test loss = 0.4054, test accuracy = 0.7705\n",
      "Epoch 457: train loss = 0.4747, test loss = 0.4052, test accuracy = 0.7705\n",
      "Epoch 458: train loss = 0.4564, test loss = 0.4053, test accuracy = 0.7705\n",
      "Epoch 459: train loss = 0.5071, test loss = 0.4052, test accuracy = 0.7705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460: train loss = 0.4170, test loss = 0.4050, test accuracy = 0.7705\n",
      "Epoch 461: train loss = 0.4617, test loss = 0.4047, test accuracy = 0.7705\n",
      "Epoch 462: train loss = 0.4293, test loss = 0.4046, test accuracy = 0.7705\n",
      "Epoch 463: train loss = 0.4343, test loss = 0.4046, test accuracy = 0.7705\n",
      "Epoch 464: train loss = 0.4106, test loss = 0.4047, test accuracy = 0.7705\n",
      "Epoch 465: train loss = 0.3897, test loss = 0.4047, test accuracy = 0.7705\n",
      "Epoch 466: train loss = 0.3950, test loss = 0.4048, test accuracy = 0.7705\n",
      "Epoch 467: train loss = 0.4080, test loss = 0.4050, test accuracy = 0.7705\n",
      "Epoch 468: train loss = 0.4522, test loss = 0.4053, test accuracy = 0.7705\n",
      "Epoch 469: train loss = 0.4366, test loss = 0.4054, test accuracy = 0.7869\n",
      "Epoch 470: train loss = 0.5015, test loss = 0.4054, test accuracy = 0.7869\n",
      "Epoch 471: train loss = 0.4072, test loss = 0.4053, test accuracy = 0.7869\n",
      "Epoch 472: train loss = 0.4616, test loss = 0.4048, test accuracy = 0.7869\n",
      "Epoch 473: train loss = 0.4584, test loss = 0.4041, test accuracy = 0.7869\n",
      "Epoch 474: train loss = 0.4267, test loss = 0.4035, test accuracy = 0.7705\n",
      "Epoch 475: train loss = 0.4098, test loss = 0.4029, test accuracy = 0.7705\n",
      "Epoch 476: train loss = 0.4250, test loss = 0.4025, test accuracy = 0.7705\n",
      "Epoch 477: train loss = 0.4538, test loss = 0.4022, test accuracy = 0.7705\n",
      "Epoch 478: train loss = 0.4627, test loss = 0.4018, test accuracy = 0.7705\n",
      "Epoch 479: train loss = 0.4386, test loss = 0.4016, test accuracy = 0.7705\n",
      "Epoch 480: train loss = 0.4685, test loss = 0.4014, test accuracy = 0.7705\n",
      "Epoch 481: train loss = 0.4362, test loss = 0.4012, test accuracy = 0.7705\n",
      "Epoch 482: train loss = 0.4222, test loss = 0.4011, test accuracy = 0.7705\n",
      "Epoch 483: train loss = 0.4615, test loss = 0.4011, test accuracy = 0.7705\n",
      "Epoch 484: train loss = 0.4292, test loss = 0.4012, test accuracy = 0.7705\n",
      "Epoch 485: train loss = 0.4226, test loss = 0.4013, test accuracy = 0.7705\n",
      "Epoch 486: train loss = 0.4703, test loss = 0.4015, test accuracy = 0.7705\n",
      "Epoch 487: train loss = 0.4229, test loss = 0.4018, test accuracy = 0.7705\n",
      "Epoch 488: train loss = 0.4402, test loss = 0.4022, test accuracy = 0.7869\n",
      "Epoch 489: train loss = 0.4359, test loss = 0.4027, test accuracy = 0.7869\n",
      "Epoch 490: train loss = 0.4169, test loss = 0.4032, test accuracy = 0.7869\n",
      "Epoch 491: train loss = 0.4622, test loss = 0.4036, test accuracy = 0.7869\n",
      "Epoch 492: train loss = 0.4483, test loss = 0.4040, test accuracy = 0.7869\n",
      "Epoch 493: train loss = 0.4574, test loss = 0.4042, test accuracy = 0.7869\n",
      "Epoch 494: train loss = 0.4046, test loss = 0.4042, test accuracy = 0.7705\n",
      "Epoch 495: train loss = 0.4275, test loss = 0.4044, test accuracy = 0.7705\n",
      "Epoch 496: train loss = 0.4350, test loss = 0.4047, test accuracy = 0.7705\n",
      "Epoch 497: train loss = 0.4089, test loss = 0.4048, test accuracy = 0.7705\n",
      "Epoch 498: train loss = 0.4368, test loss = 0.4049, test accuracy = 0.7705\n",
      "Epoch 499: train loss = 0.3847, test loss = 0.4046, test accuracy = 0.7705\n",
      "Epoch 500: train loss = 0.4710, test loss = 0.4041, test accuracy = 0.7869\n",
      "Epoch 501: train loss = 0.4176, test loss = 0.4036, test accuracy = 0.7869\n",
      "Epoch 502: train loss = 0.4222, test loss = 0.4031, test accuracy = 0.7869\n",
      "Epoch 503: train loss = 0.4924, test loss = 0.4026, test accuracy = 0.7869\n",
      "Epoch 504: train loss = 0.4693, test loss = 0.4024, test accuracy = 0.7869\n",
      "Epoch 505: train loss = 0.4353, test loss = 0.4021, test accuracy = 0.7869\n",
      "Epoch 506: train loss = 0.4260, test loss = 0.4020, test accuracy = 0.7869\n",
      "Epoch 507: train loss = 0.4929, test loss = 0.4018, test accuracy = 0.7705\n",
      "Epoch 508: train loss = 0.4577, test loss = 0.4014, test accuracy = 0.7705\n",
      "Epoch 509: train loss = 0.3899, test loss = 0.4010, test accuracy = 0.7705\n",
      "Epoch 510: train loss = 0.4365, test loss = 0.4006, test accuracy = 0.7705\n",
      "Epoch 511: train loss = 0.4140, test loss = 0.4003, test accuracy = 0.7705\n",
      "Epoch 512: train loss = 0.4141, test loss = 0.4002, test accuracy = 0.7705\n",
      "Epoch 513: train loss = 0.4366, test loss = 0.4000, test accuracy = 0.7705\n",
      "Epoch 514: train loss = 0.4099, test loss = 0.4001, test accuracy = 0.7705\n",
      "Epoch 515: train loss = 0.4244, test loss = 0.4002, test accuracy = 0.7705\n",
      "Epoch 516: train loss = 0.4524, test loss = 0.4006, test accuracy = 0.7705\n",
      "Epoch 517: train loss = 0.4660, test loss = 0.4009, test accuracy = 0.7705\n",
      "Epoch 518: train loss = 0.4480, test loss = 0.4014, test accuracy = 0.7869\n",
      "Epoch 519: train loss = 0.4896, test loss = 0.4020, test accuracy = 0.7869\n",
      "Epoch 520: train loss = 0.4504, test loss = 0.4027, test accuracy = 0.7869\n",
      "Epoch 521: train loss = 0.4477, test loss = 0.4031, test accuracy = 0.7869\n",
      "Epoch 522: train loss = 0.4756, test loss = 0.4034, test accuracy = 0.7705\n",
      "Epoch 523: train loss = 0.4446, test loss = 0.4037, test accuracy = 0.7705\n",
      "Epoch 524: train loss = 0.4066, test loss = 0.4037, test accuracy = 0.7705\n",
      "Epoch 525: train loss = 0.4677, test loss = 0.4037, test accuracy = 0.7705\n",
      "Epoch 526: train loss = 0.4810, test loss = 0.4039, test accuracy = 0.7705\n",
      "Epoch 527: train loss = 0.4333, test loss = 0.4037, test accuracy = 0.7705\n",
      "Epoch 528: train loss = 0.4217, test loss = 0.4033, test accuracy = 0.7705\n",
      "Epoch 529: train loss = 0.4382, test loss = 0.4030, test accuracy = 0.7869\n",
      "Epoch 530: train loss = 0.4239, test loss = 0.4031, test accuracy = 0.7869\n",
      "Epoch 531: train loss = 0.4661, test loss = 0.4032, test accuracy = 0.7869\n",
      "Epoch 532: train loss = 0.4352, test loss = 0.4031, test accuracy = 0.7869\n",
      "Epoch 533: train loss = 0.4339, test loss = 0.4028, test accuracy = 0.7869\n",
      "Epoch 534: train loss = 0.4054, test loss = 0.4026, test accuracy = 0.7869\n",
      "Epoch 535: train loss = 0.4421, test loss = 0.4024, test accuracy = 0.7869\n",
      "Epoch 536: train loss = 0.4036, test loss = 0.4021, test accuracy = 0.7869\n",
      "Epoch 537: train loss = 0.4409, test loss = 0.4017, test accuracy = 0.7869\n",
      "Epoch 538: train loss = 0.4313, test loss = 0.4014, test accuracy = 0.7869\n",
      "Epoch 539: train loss = 0.4153, test loss = 0.4010, test accuracy = 0.7705\n",
      "Epoch 540: train loss = 0.4423, test loss = 0.4008, test accuracy = 0.7705\n",
      "Epoch 541: train loss = 0.4674, test loss = 0.4005, test accuracy = 0.7705\n",
      "Epoch 542: train loss = 0.4515, test loss = 0.4005, test accuracy = 0.7705\n",
      "Epoch 543: train loss = 0.4455, test loss = 0.4005, test accuracy = 0.7705\n",
      "Epoch 544: train loss = 0.3977, test loss = 0.4007, test accuracy = 0.7705\n",
      "Epoch 545: train loss = 0.4089, test loss = 0.4008, test accuracy = 0.7869\n",
      "Epoch 546: train loss = 0.3628, test loss = 0.4008, test accuracy = 0.7869\n",
      "Epoch 547: train loss = 0.4232, test loss = 0.4009, test accuracy = 0.7869\n",
      "Epoch 548: train loss = 0.4564, test loss = 0.4011, test accuracy = 0.7869\n",
      "Epoch 549: train loss = 0.4348, test loss = 0.4015, test accuracy = 0.7869\n",
      "Epoch 550: train loss = 0.4084, test loss = 0.4019, test accuracy = 0.7869\n",
      "Epoch 551: train loss = 0.3996, test loss = 0.4020, test accuracy = 0.7869\n",
      "Epoch 552: train loss = 0.4237, test loss = 0.4019, test accuracy = 0.7869\n",
      "Epoch 553: train loss = 0.4089, test loss = 0.4020, test accuracy = 0.7705\n",
      "Epoch 554: train loss = 0.4176, test loss = 0.4021, test accuracy = 0.7705\n",
      "Epoch 555: train loss = 0.4132, test loss = 0.4022, test accuracy = 0.7705\n",
      "Epoch 556: train loss = 0.4241, test loss = 0.4020, test accuracy = 0.7705\n",
      "Epoch 557: train loss = 0.4319, test loss = 0.4019, test accuracy = 0.7705\n",
      "Epoch 558: train loss = 0.4087, test loss = 0.4018, test accuracy = 0.7869\n",
      "Epoch 559: train loss = 0.4018, test loss = 0.4015, test accuracy = 0.7869\n",
      "Epoch 560: train loss = 0.4301, test loss = 0.4011, test accuracy = 0.7869\n",
      "Epoch 561: train loss = 0.3985, test loss = 0.4007, test accuracy = 0.7869\n",
      "Epoch 562: train loss = 0.4261, test loss = 0.4004, test accuracy = 0.7869\n",
      "Epoch 563: train loss = 0.4691, test loss = 0.4002, test accuracy = 0.7869\n",
      "Epoch 564: train loss = 0.4406, test loss = 0.4001, test accuracy = 0.7869\n",
      "Epoch 565: train loss = 0.3894, test loss = 0.3999, test accuracy = 0.7869\n",
      "Epoch 566: train loss = 0.4497, test loss = 0.3997, test accuracy = 0.7705\n",
      "Epoch 567: train loss = 0.4154, test loss = 0.3994, test accuracy = 0.7705\n",
      "Epoch 568: train loss = 0.4687, test loss = 0.3993, test accuracy = 0.7705\n",
      "Epoch 569: train loss = 0.4178, test loss = 0.3992, test accuracy = 0.7705\n",
      "Epoch 570: train loss = 0.4259, test loss = 0.3993, test accuracy = 0.7705\n",
      "Epoch 571: train loss = 0.4715, test loss = 0.3993, test accuracy = 0.7705\n",
      "Epoch 572: train loss = 0.4119, test loss = 0.3995, test accuracy = 0.7869\n",
      "Epoch 573: train loss = 0.4477, test loss = 0.3997, test accuracy = 0.7869\n",
      "Epoch 574: train loss = 0.3965, test loss = 0.4000, test accuracy = 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 575: train loss = 0.4859, test loss = 0.4004, test accuracy = 0.7869\n",
      "Epoch 576: train loss = 0.4763, test loss = 0.4005, test accuracy = 0.7869\n",
      "Epoch 577: train loss = 0.4266, test loss = 0.4006, test accuracy = 0.7869\n",
      "Epoch 578: train loss = 0.4527, test loss = 0.4005, test accuracy = 0.7869\n",
      "Epoch 579: train loss = 0.4354, test loss = 0.4004, test accuracy = 0.7869\n",
      "Epoch 580: train loss = 0.4111, test loss = 0.4004, test accuracy = 0.7869\n",
      "Epoch 581: train loss = 0.4360, test loss = 0.4002, test accuracy = 0.7869\n",
      "Epoch 582: train loss = 0.4408, test loss = 0.4000, test accuracy = 0.7869\n",
      "Epoch 583: train loss = 0.4620, test loss = 0.3998, test accuracy = 0.7869\n",
      "Epoch 584: train loss = 0.4238, test loss = 0.3998, test accuracy = 0.7869\n",
      "Epoch 585: train loss = 0.4050, test loss = 0.4000, test accuracy = 0.7705\n",
      "Epoch 586: train loss = 0.4284, test loss = 0.4002, test accuracy = 0.7705\n",
      "Epoch 587: train loss = 0.4306, test loss = 0.4004, test accuracy = 0.7705\n",
      "Epoch 588: train loss = 0.4095, test loss = 0.4002, test accuracy = 0.7705\n",
      "Epoch 589: train loss = 0.4282, test loss = 0.3999, test accuracy = 0.7705\n",
      "Epoch 590: train loss = 0.4116, test loss = 0.3995, test accuracy = 0.7705\n",
      "Epoch 591: train loss = 0.4549, test loss = 0.3990, test accuracy = 0.7869\n",
      "Epoch 592: train loss = 0.3854, test loss = 0.3986, test accuracy = 0.7869\n",
      "Epoch 593: train loss = 0.4328, test loss = 0.3981, test accuracy = 0.7869\n",
      "Epoch 594: train loss = 0.4231, test loss = 0.3976, test accuracy = 0.7869\n",
      "Epoch 595: train loss = 0.4147, test loss = 0.3971, test accuracy = 0.7869\n",
      "Epoch 596: train loss = 0.4621, test loss = 0.3967, test accuracy = 0.7869\n",
      "Epoch 597: train loss = 0.4451, test loss = 0.3962, test accuracy = 0.7869\n",
      "Epoch 598: train loss = 0.4186, test loss = 0.3958, test accuracy = 0.7869\n",
      "Epoch 599: train loss = 0.4098, test loss = 0.3954, test accuracy = 0.7869\n",
      "Epoch 600: train loss = 0.4037, test loss = 0.3951, test accuracy = 0.7705\n",
      "Epoch 601: train loss = 0.4667, test loss = 0.3948, test accuracy = 0.7705\n",
      "Epoch 602: train loss = 0.4198, test loss = 0.3946, test accuracy = 0.7705\n",
      "Epoch 603: train loss = 0.4184, test loss = 0.3944, test accuracy = 0.7705\n",
      "Epoch 604: train loss = 0.4237, test loss = 0.3943, test accuracy = 0.7705\n",
      "Epoch 605: train loss = 0.4158, test loss = 0.3942, test accuracy = 0.7705\n",
      "Epoch 606: train loss = 0.4038, test loss = 0.3942, test accuracy = 0.7705\n",
      "Epoch 607: train loss = 0.4243, test loss = 0.3941, test accuracy = 0.7869\n",
      "Epoch 608: train loss = 0.5045, test loss = 0.3942, test accuracy = 0.7869\n",
      "Epoch 609: train loss = 0.4140, test loss = 0.3943, test accuracy = 0.7869\n",
      "Epoch 610: train loss = 0.4712, test loss = 0.3945, test accuracy = 0.7869\n",
      "Epoch 611: train loss = 0.4503, test loss = 0.3946, test accuracy = 0.7869\n",
      "Epoch 612: train loss = 0.4188, test loss = 0.3948, test accuracy = 0.7869\n",
      "Epoch 613: train loss = 0.4215, test loss = 0.3948, test accuracy = 0.7869\n",
      "Epoch 614: train loss = 0.4306, test loss = 0.3946, test accuracy = 0.7869\n",
      "Epoch 615: train loss = 0.4031, test loss = 0.3946, test accuracy = 0.7869\n",
      "Epoch 616: train loss = 0.4223, test loss = 0.3946, test accuracy = 0.7869\n",
      "Epoch 617: train loss = 0.4092, test loss = 0.3945, test accuracy = 0.7869\n",
      "Epoch 618: train loss = 0.4504, test loss = 0.3943, test accuracy = 0.7869\n",
      "Epoch 619: train loss = 0.4354, test loss = 0.3941, test accuracy = 0.7869\n",
      "Epoch 620: train loss = 0.4293, test loss = 0.3941, test accuracy = 0.7869\n",
      "Epoch 621: train loss = 0.4364, test loss = 0.3941, test accuracy = 0.7869\n",
      "Epoch 622: train loss = 0.4103, test loss = 0.3938, test accuracy = 0.7869\n",
      "Epoch 623: train loss = 0.3988, test loss = 0.3935, test accuracy = 0.7869\n",
      "Epoch 624: train loss = 0.3932, test loss = 0.3932, test accuracy = 0.7869\n",
      "Epoch 625: train loss = 0.4492, test loss = 0.3928, test accuracy = 0.7869\n",
      "Epoch 626: train loss = 0.4330, test loss = 0.3926, test accuracy = 0.7869\n",
      "Epoch 627: train loss = 0.4182, test loss = 0.3924, test accuracy = 0.7869\n",
      "Epoch 628: train loss = 0.4746, test loss = 0.3920, test accuracy = 0.7869\n",
      "Epoch 629: train loss = 0.4375, test loss = 0.3915, test accuracy = 0.7869\n",
      "Epoch 630: train loss = 0.4317, test loss = 0.3909, test accuracy = 0.7869\n",
      "Epoch 631: train loss = 0.4342, test loss = 0.3905, test accuracy = 0.7869\n",
      "Epoch 632: train loss = 0.4233, test loss = 0.3902, test accuracy = 0.7869\n",
      "Epoch 633: train loss = 0.4295, test loss = 0.3900, test accuracy = 0.7869\n",
      "Epoch 634: train loss = 0.4376, test loss = 0.3896, test accuracy = 0.7869\n",
      "Epoch 635: train loss = 0.4510, test loss = 0.3893, test accuracy = 0.7869\n",
      "Epoch 636: train loss = 0.4219, test loss = 0.3891, test accuracy = 0.7869\n",
      "Epoch 637: train loss = 0.3827, test loss = 0.3888, test accuracy = 0.7869\n",
      "Epoch 638: train loss = 0.4452, test loss = 0.3887, test accuracy = 0.7869\n",
      "Epoch 639: train loss = 0.3727, test loss = 0.3886, test accuracy = 0.7869\n",
      "Epoch 640: train loss = 0.4017, test loss = 0.3886, test accuracy = 0.7869\n",
      "Epoch 641: train loss = 0.4197, test loss = 0.3887, test accuracy = 0.7869\n",
      "Epoch 642: train loss = 0.3735, test loss = 0.3890, test accuracy = 0.7869\n",
      "Epoch 643: train loss = 0.4095, test loss = 0.3892, test accuracy = 0.7869\n",
      "Epoch 644: train loss = 0.4470, test loss = 0.3892, test accuracy = 0.7869\n",
      "Epoch 645: train loss = 0.4045, test loss = 0.3892, test accuracy = 0.7869\n",
      "Epoch 646: train loss = 0.4215, test loss = 0.3891, test accuracy = 0.7869\n",
      "Epoch 647: train loss = 0.4017, test loss = 0.3888, test accuracy = 0.7869\n",
      "Epoch 648: train loss = 0.4034, test loss = 0.3886, test accuracy = 0.7869\n",
      "Epoch 649: train loss = 0.4021, test loss = 0.3885, test accuracy = 0.7869\n",
      "Epoch 650: train loss = 0.4198, test loss = 0.3882, test accuracy = 0.7869\n",
      "Epoch 651: train loss = 0.4371, test loss = 0.3881, test accuracy = 0.7869\n",
      "Epoch 652: train loss = 0.4251, test loss = 0.3883, test accuracy = 0.7869\n",
      "Epoch 653: train loss = 0.3783, test loss = 0.3883, test accuracy = 0.7869\n",
      "Epoch 654: train loss = 0.4213, test loss = 0.3884, test accuracy = 0.7869\n",
      "Epoch 655: train loss = 0.4656, test loss = 0.3884, test accuracy = 0.7869\n",
      "Epoch 656: train loss = 0.4282, test loss = 0.3885, test accuracy = 0.7869\n",
      "Epoch 657: train loss = 0.4055, test loss = 0.3884, test accuracy = 0.7869\n",
      "Epoch 658: train loss = 0.3591, test loss = 0.3883, test accuracy = 0.7869\n",
      "Epoch 659: train loss = 0.4395, test loss = 0.3883, test accuracy = 0.7869\n",
      "Epoch 660: train loss = 0.4317, test loss = 0.3883, test accuracy = 0.7869\n",
      "Epoch 661: train loss = 0.4189, test loss = 0.3885, test accuracy = 0.7869\n",
      "Epoch 662: train loss = 0.3821, test loss = 0.3882, test accuracy = 0.7869\n",
      "Epoch 663: train loss = 0.3850, test loss = 0.3877, test accuracy = 0.7869\n",
      "Epoch 664: train loss = 0.4297, test loss = 0.3872, test accuracy = 0.7869\n",
      "Epoch 665: train loss = 0.3908, test loss = 0.3867, test accuracy = 0.7869\n",
      "Epoch 666: train loss = 0.4145, test loss = 0.3862, test accuracy = 0.7869\n",
      "Epoch 667: train loss = 0.4398, test loss = 0.3857, test accuracy = 0.7869\n",
      "Epoch 668: train loss = 0.3888, test loss = 0.3852, test accuracy = 0.7869\n",
      "Epoch 669: train loss = 0.4059, test loss = 0.3849, test accuracy = 0.7869\n",
      "Epoch 670: train loss = 0.4379, test loss = 0.3847, test accuracy = 0.7869\n",
      "Epoch 671: train loss = 0.4240, test loss = 0.3844, test accuracy = 0.7869\n",
      "Epoch 672: train loss = 0.4376, test loss = 0.3843, test accuracy = 0.7869\n",
      "Epoch 673: train loss = 0.3841, test loss = 0.3843, test accuracy = 0.7869\n",
      "Epoch 674: train loss = 0.4254, test loss = 0.3843, test accuracy = 0.7869\n",
      "Epoch 675: train loss = 0.3944, test loss = 0.3843, test accuracy = 0.7869\n",
      "Epoch 676: train loss = 0.4301, test loss = 0.3845, test accuracy = 0.7869\n",
      "Epoch 677: train loss = 0.4176, test loss = 0.3846, test accuracy = 0.7869\n",
      "Epoch 678: train loss = 0.4585, test loss = 0.3848, test accuracy = 0.7869\n",
      "Epoch 679: train loss = 0.4412, test loss = 0.3852, test accuracy = 0.7869\n",
      "Epoch 680: train loss = 0.4669, test loss = 0.3854, test accuracy = 0.7869\n",
      "Epoch 681: train loss = 0.4143, test loss = 0.3857, test accuracy = 0.7869\n",
      "Epoch 682: train loss = 0.4180, test loss = 0.3858, test accuracy = 0.7869\n",
      "Epoch 683: train loss = 0.4218, test loss = 0.3857, test accuracy = 0.7869\n",
      "Epoch 684: train loss = 0.4061, test loss = 0.3855, test accuracy = 0.7869\n",
      "Epoch 685: train loss = 0.3946, test loss = 0.3856, test accuracy = 0.7869\n",
      "Epoch 686: train loss = 0.4010, test loss = 0.3856, test accuracy = 0.7869\n",
      "Epoch 687: train loss = 0.4333, test loss = 0.3857, test accuracy = 0.7869\n",
      "Epoch 688: train loss = 0.3985, test loss = 0.3856, test accuracy = 0.7869\n",
      "Epoch 689: train loss = 0.3852, test loss = 0.3855, test accuracy = 0.7869\n",
      "Epoch 690: train loss = 0.4305, test loss = 0.3856, test accuracy = 0.7869\n",
      "Epoch 691: train loss = 0.4209, test loss = 0.3853, test accuracy = 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692: train loss = 0.4078, test loss = 0.3852, test accuracy = 0.7869\n",
      "Epoch 693: train loss = 0.3901, test loss = 0.3850, test accuracy = 0.7869\n",
      "Epoch 694: train loss = 0.4037, test loss = 0.3847, test accuracy = 0.7869\n",
      "Epoch 695: train loss = 0.3725, test loss = 0.3843, test accuracy = 0.7869\n",
      "Epoch 696: train loss = 0.3912, test loss = 0.3839, test accuracy = 0.7869\n",
      "Epoch 697: train loss = 0.4226, test loss = 0.3835, test accuracy = 0.7869\n",
      "Epoch 698: train loss = 0.4386, test loss = 0.3833, test accuracy = 0.7869\n",
      "Epoch 699: train loss = 0.4107, test loss = 0.3830, test accuracy = 0.7869\n",
      "Epoch 700: train loss = 0.4312, test loss = 0.3829, test accuracy = 0.7869\n",
      "Epoch 701: train loss = 0.4372, test loss = 0.3826, test accuracy = 0.7869\n",
      "Epoch 702: train loss = 0.4325, test loss = 0.3824, test accuracy = 0.7869\n",
      "Epoch 703: train loss = 0.4401, test loss = 0.3823, test accuracy = 0.7869\n",
      "Epoch 704: train loss = 0.4111, test loss = 0.3823, test accuracy = 0.7869\n",
      "Epoch 705: train loss = 0.4290, test loss = 0.3823, test accuracy = 0.7869\n",
      "Epoch 706: train loss = 0.4184, test loss = 0.3822, test accuracy = 0.7869\n",
      "Epoch 707: train loss = 0.3793, test loss = 0.3819, test accuracy = 0.7869\n",
      "Epoch 708: train loss = 0.3787, test loss = 0.3815, test accuracy = 0.7869\n",
      "Epoch 709: train loss = 0.4230, test loss = 0.3811, test accuracy = 0.7869\n",
      "Epoch 710: train loss = 0.4211, test loss = 0.3808, test accuracy = 0.7869\n",
      "Epoch 711: train loss = 0.4381, test loss = 0.3805, test accuracy = 0.7869\n",
      "Epoch 712: train loss = 0.4147, test loss = 0.3800, test accuracy = 0.7869\n",
      "Epoch 713: train loss = 0.3952, test loss = 0.3797, test accuracy = 0.7869\n",
      "Epoch 714: train loss = 0.4269, test loss = 0.3793, test accuracy = 0.7869\n",
      "Epoch 715: train loss = 0.4496, test loss = 0.3792, test accuracy = 0.8033\n",
      "Epoch 716: train loss = 0.3686, test loss = 0.3791, test accuracy = 0.8033\n",
      "Epoch 717: train loss = 0.4113, test loss = 0.3791, test accuracy = 0.7869\n",
      "Epoch 718: train loss = 0.4482, test loss = 0.3792, test accuracy = 0.7869\n",
      "Epoch 719: train loss = 0.3942, test loss = 0.3793, test accuracy = 0.7869\n",
      "Epoch 720: train loss = 0.3998, test loss = 0.3796, test accuracy = 0.7869\n",
      "Epoch 721: train loss = 0.4300, test loss = 0.3800, test accuracy = 0.7869\n",
      "Epoch 722: train loss = 0.4070, test loss = 0.3801, test accuracy = 0.7869\n",
      "Epoch 723: train loss = 0.3846, test loss = 0.3804, test accuracy = 0.8033\n",
      "Epoch 724: train loss = 0.4240, test loss = 0.3806, test accuracy = 0.8033\n",
      "Epoch 725: train loss = 0.4216, test loss = 0.3803, test accuracy = 0.8033\n",
      "Epoch 726: train loss = 0.3804, test loss = 0.3798, test accuracy = 0.8033\n",
      "Epoch 727: train loss = 0.3802, test loss = 0.3793, test accuracy = 0.7869\n",
      "Epoch 728: train loss = 0.4358, test loss = 0.3788, test accuracy = 0.7869\n",
      "Epoch 729: train loss = 0.3683, test loss = 0.3783, test accuracy = 0.8033\n",
      "Epoch 730: train loss = 0.4331, test loss = 0.3780, test accuracy = 0.8033\n",
      "Epoch 731: train loss = 0.4077, test loss = 0.3779, test accuracy = 0.8033\n",
      "Epoch 732: train loss = 0.4139, test loss = 0.3778, test accuracy = 0.8033\n",
      "Epoch 733: train loss = 0.4368, test loss = 0.3777, test accuracy = 0.8033\n",
      "Epoch 734: train loss = 0.3712, test loss = 0.3776, test accuracy = 0.8033\n",
      "Epoch 735: train loss = 0.4155, test loss = 0.3776, test accuracy = 0.8033\n",
      "Epoch 736: train loss = 0.3728, test loss = 0.3777, test accuracy = 0.8033\n",
      "Epoch 737: train loss = 0.4400, test loss = 0.3775, test accuracy = 0.8033\n",
      "Epoch 738: train loss = 0.4109, test loss = 0.3774, test accuracy = 0.8033\n",
      "Epoch 739: train loss = 0.4245, test loss = 0.3774, test accuracy = 0.8033\n",
      "Epoch 740: train loss = 0.4460, test loss = 0.3777, test accuracy = 0.8033\n",
      "Epoch 741: train loss = 0.3975, test loss = 0.3782, test accuracy = 0.8033\n",
      "Epoch 742: train loss = 0.4143, test loss = 0.3786, test accuracy = 0.8033\n",
      "Epoch 743: train loss = 0.4235, test loss = 0.3792, test accuracy = 0.8033\n",
      "Epoch 744: train loss = 0.4195, test loss = 0.3799, test accuracy = 0.8033\n",
      "Epoch 745: train loss = 0.3489, test loss = 0.3807, test accuracy = 0.8033\n",
      "Epoch 746: train loss = 0.3796, test loss = 0.3814, test accuracy = 0.8033\n",
      "Epoch 747: train loss = 0.4279, test loss = 0.3819, test accuracy = 0.8033\n",
      "Epoch 748: train loss = 0.4583, test loss = 0.3822, test accuracy = 0.8197\n",
      "Epoch 749: train loss = 0.3814, test loss = 0.3823, test accuracy = 0.8197\n",
      "Epoch 750: train loss = 0.4051, test loss = 0.3822, test accuracy = 0.8361\n",
      "Epoch 751: train loss = 0.4442, test loss = 0.3818, test accuracy = 0.8197\n",
      "Epoch 752: train loss = 0.4090, test loss = 0.3814, test accuracy = 0.8197\n",
      "Epoch 753: train loss = 0.3818, test loss = 0.3810, test accuracy = 0.8197\n",
      "Epoch 754: train loss = 0.3995, test loss = 0.3804, test accuracy = 0.8197\n",
      "Epoch 755: train loss = 0.4346, test loss = 0.3800, test accuracy = 0.8197\n",
      "Epoch 756: train loss = 0.4050, test loss = 0.3793, test accuracy = 0.8197\n",
      "Epoch 757: train loss = 0.4379, test loss = 0.3788, test accuracy = 0.8033\n",
      "Epoch 758: train loss = 0.4191, test loss = 0.3785, test accuracy = 0.8033\n",
      "Epoch 759: train loss = 0.3938, test loss = 0.3782, test accuracy = 0.8033\n",
      "Epoch 760: train loss = 0.4240, test loss = 0.3779, test accuracy = 0.8033\n",
      "Epoch 761: train loss = 0.4018, test loss = 0.3777, test accuracy = 0.8033\n",
      "Epoch 762: train loss = 0.4367, test loss = 0.3774, test accuracy = 0.7869\n",
      "Epoch 763: train loss = 0.4641, test loss = 0.3771, test accuracy = 0.7869\n",
      "Epoch 764: train loss = 0.4182, test loss = 0.3769, test accuracy = 0.8033\n",
      "Epoch 765: train loss = 0.4390, test loss = 0.3768, test accuracy = 0.8033\n",
      "Epoch 766: train loss = 0.4419, test loss = 0.3769, test accuracy = 0.8033\n",
      "Epoch 767: train loss = 0.4035, test loss = 0.3770, test accuracy = 0.8033\n",
      "Epoch 768: train loss = 0.3976, test loss = 0.3773, test accuracy = 0.8197\n",
      "Epoch 769: train loss = 0.3800, test loss = 0.3775, test accuracy = 0.8197\n",
      "Epoch 770: train loss = 0.4244, test loss = 0.3778, test accuracy = 0.8197\n",
      "Epoch 771: train loss = 0.4283, test loss = 0.3780, test accuracy = 0.8197\n",
      "Epoch 772: train loss = 0.3913, test loss = 0.3781, test accuracy = 0.8197\n",
      "Epoch 773: train loss = 0.3697, test loss = 0.3782, test accuracy = 0.8197\n",
      "Epoch 774: train loss = 0.3803, test loss = 0.3781, test accuracy = 0.8197\n",
      "Epoch 775: train loss = 0.4020, test loss = 0.3780, test accuracy = 0.8361\n",
      "Epoch 776: train loss = 0.3659, test loss = 0.3778, test accuracy = 0.8361\n",
      "Epoch 777: train loss = 0.4219, test loss = 0.3775, test accuracy = 0.8361\n",
      "Epoch 778: train loss = 0.4028, test loss = 0.3770, test accuracy = 0.8197\n",
      "Epoch 779: train loss = 0.4128, test loss = 0.3764, test accuracy = 0.8197\n",
      "Epoch 780: train loss = 0.3916, test loss = 0.3760, test accuracy = 0.8197\n",
      "Epoch 781: train loss = 0.4064, test loss = 0.3757, test accuracy = 0.8197\n",
      "Epoch 782: train loss = 0.3820, test loss = 0.3755, test accuracy = 0.8197\n",
      "Epoch 783: train loss = 0.4038, test loss = 0.3752, test accuracy = 0.8361\n",
      "Epoch 784: train loss = 0.4205, test loss = 0.3749, test accuracy = 0.8361\n",
      "Epoch 785: train loss = 0.3980, test loss = 0.3745, test accuracy = 0.8361\n",
      "Epoch 786: train loss = 0.3646, test loss = 0.3743, test accuracy = 0.8361\n",
      "Epoch 787: train loss = 0.4300, test loss = 0.3742, test accuracy = 0.8361\n",
      "Epoch 788: train loss = 0.4139, test loss = 0.3742, test accuracy = 0.8361\n",
      "Epoch 789: train loss = 0.4089, test loss = 0.3742, test accuracy = 0.8361\n",
      "Epoch 790: train loss = 0.3927, test loss = 0.3743, test accuracy = 0.8361\n",
      "Epoch 791: train loss = 0.4481, test loss = 0.3741, test accuracy = 0.8361\n",
      "Epoch 792: train loss = 0.4146, test loss = 0.3739, test accuracy = 0.8361\n",
      "Epoch 793: train loss = 0.3729, test loss = 0.3737, test accuracy = 0.8361\n",
      "Epoch 794: train loss = 0.4188, test loss = 0.3739, test accuracy = 0.8361\n",
      "Epoch 795: train loss = 0.3942, test loss = 0.3741, test accuracy = 0.8361\n",
      "Epoch 796: train loss = 0.4070, test loss = 0.3741, test accuracy = 0.8361\n",
      "Epoch 797: train loss = 0.4122, test loss = 0.3743, test accuracy = 0.8525\n",
      "Epoch 798: train loss = 0.4123, test loss = 0.3745, test accuracy = 0.8361\n",
      "Epoch 799: train loss = 0.3783, test loss = 0.3750, test accuracy = 0.8361\n",
      "Epoch 800: train loss = 0.4372, test loss = 0.3752, test accuracy = 0.8361\n",
      "Epoch 801: train loss = 0.3960, test loss = 0.3752, test accuracy = 0.8361\n",
      "Epoch 802: train loss = 0.3839, test loss = 0.3750, test accuracy = 0.8361\n",
      "Epoch 803: train loss = 0.4030, test loss = 0.3746, test accuracy = 0.8361\n",
      "Epoch 804: train loss = 0.4199, test loss = 0.3741, test accuracy = 0.8525\n",
      "Epoch 805: train loss = 0.4338, test loss = 0.3738, test accuracy = 0.8525\n",
      "Epoch 806: train loss = 0.4039, test loss = 0.3735, test accuracy = 0.8525\n",
      "Epoch 807: train loss = 0.4045, test loss = 0.3734, test accuracy = 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 808: train loss = 0.4121, test loss = 0.3734, test accuracy = 0.8525\n",
      "Epoch 809: train loss = 0.4170, test loss = 0.3736, test accuracy = 0.8525\n",
      "Epoch 810: train loss = 0.3935, test loss = 0.3739, test accuracy = 0.8525\n",
      "Epoch 811: train loss = 0.4179, test loss = 0.3740, test accuracy = 0.8361\n",
      "Epoch 812: train loss = 0.3962, test loss = 0.3741, test accuracy = 0.8361\n",
      "Epoch 813: train loss = 0.4383, test loss = 0.3742, test accuracy = 0.8361\n",
      "Epoch 814: train loss = 0.4213, test loss = 0.3742, test accuracy = 0.8361\n",
      "Epoch 815: train loss = 0.4397, test loss = 0.3741, test accuracy = 0.8361\n",
      "Epoch 816: train loss = 0.3660, test loss = 0.3742, test accuracy = 0.8361\n",
      "Epoch 817: train loss = 0.4027, test loss = 0.3744, test accuracy = 0.8361\n",
      "Epoch 818: train loss = 0.4162, test loss = 0.3742, test accuracy = 0.8361\n",
      "Epoch 819: train loss = 0.4256, test loss = 0.3740, test accuracy = 0.8361\n",
      "Epoch 820: train loss = 0.4494, test loss = 0.3738, test accuracy = 0.8361\n",
      "Epoch 821: train loss = 0.4330, test loss = 0.3736, test accuracy = 0.8525\n",
      "Epoch 822: train loss = 0.3897, test loss = 0.3736, test accuracy = 0.8525\n",
      "Epoch 823: train loss = 0.3768, test loss = 0.3735, test accuracy = 0.8525\n",
      "Epoch 824: train loss = 0.3982, test loss = 0.3736, test accuracy = 0.8525\n",
      "Epoch 825: train loss = 0.3985, test loss = 0.3737, test accuracy = 0.8525\n",
      "Epoch 826: train loss = 0.4114, test loss = 0.3735, test accuracy = 0.8525\n",
      "Epoch 827: train loss = 0.4224, test loss = 0.3734, test accuracy = 0.8525\n",
      "Epoch 828: train loss = 0.4092, test loss = 0.3731, test accuracy = 0.8525\n",
      "Epoch 829: train loss = 0.3976, test loss = 0.3730, test accuracy = 0.8525\n",
      "Epoch 830: train loss = 0.4201, test loss = 0.3729, test accuracy = 0.8525\n",
      "Epoch 831: train loss = 0.3991, test loss = 0.3729, test accuracy = 0.8525\n",
      "Epoch 832: train loss = 0.3578, test loss = 0.3728, test accuracy = 0.8525\n",
      "Epoch 833: train loss = 0.3838, test loss = 0.3728, test accuracy = 0.8525\n",
      "Epoch 834: train loss = 0.3733, test loss = 0.3729, test accuracy = 0.8525\n",
      "Epoch 835: train loss = 0.3653, test loss = 0.3731, test accuracy = 0.8525\n",
      "Epoch 836: train loss = 0.4145, test loss = 0.3734, test accuracy = 0.8361\n",
      "Epoch 837: train loss = 0.4014, test loss = 0.3739, test accuracy = 0.8361\n",
      "Epoch 838: train loss = 0.4362, test loss = 0.3742, test accuracy = 0.8361\n",
      "Epoch 839: train loss = 0.3756, test loss = 0.3744, test accuracy = 0.8361\n",
      "Epoch 840: train loss = 0.4259, test loss = 0.3742, test accuracy = 0.8361\n",
      "Epoch 841: train loss = 0.4556, test loss = 0.3738, test accuracy = 0.8361\n",
      "Epoch 842: train loss = 0.3432, test loss = 0.3736, test accuracy = 0.8361\n",
      "Epoch 843: train loss = 0.4104, test loss = 0.3733, test accuracy = 0.8525\n",
      "Epoch 844: train loss = 0.4442, test loss = 0.3730, test accuracy = 0.8525\n",
      "Epoch 845: train loss = 0.3684, test loss = 0.3727, test accuracy = 0.8525\n",
      "Epoch 846: train loss = 0.3877, test loss = 0.3727, test accuracy = 0.8525\n",
      "Epoch 847: train loss = 0.3910, test loss = 0.3729, test accuracy = 0.8525\n",
      "Epoch 848: train loss = 0.4049, test loss = 0.3729, test accuracy = 0.8525\n",
      "Epoch 849: train loss = 0.4114, test loss = 0.3730, test accuracy = 0.8525\n",
      "Epoch 850: train loss = 0.4033, test loss = 0.3730, test accuracy = 0.8525\n",
      "Epoch 851: train loss = 0.4611, test loss = 0.3728, test accuracy = 0.8525\n",
      "Epoch 852: train loss = 0.3998, test loss = 0.3728, test accuracy = 0.8525\n",
      "Epoch 853: train loss = 0.3802, test loss = 0.3729, test accuracy = 0.8525\n",
      "Epoch 854: train loss = 0.3568, test loss = 0.3730, test accuracy = 0.8525\n",
      "Epoch 855: train loss = 0.3843, test loss = 0.3729, test accuracy = 0.8525\n",
      "Epoch 856: train loss = 0.3907, test loss = 0.3729, test accuracy = 0.8525\n",
      "Epoch 857: train loss = 0.3914, test loss = 0.3730, test accuracy = 0.8525\n",
      "Epoch 858: train loss = 0.4171, test loss = 0.3733, test accuracy = 0.8525\n",
      "Epoch 859: train loss = 0.3929, test loss = 0.3737, test accuracy = 0.8361\n",
      "Epoch 860: train loss = 0.4087, test loss = 0.3744, test accuracy = 0.8361\n",
      "Epoch 861: train loss = 0.3789, test loss = 0.3751, test accuracy = 0.8361\n",
      "Epoch 862: train loss = 0.4150, test loss = 0.3755, test accuracy = 0.8361\n",
      "Epoch 863: train loss = 0.4325, test loss = 0.3757, test accuracy = 0.8361\n",
      "Epoch 864: train loss = 0.4165, test loss = 0.3758, test accuracy = 0.8361\n",
      "Epoch 865: train loss = 0.4022, test loss = 0.3755, test accuracy = 0.8361\n",
      "Epoch 866: train loss = 0.3968, test loss = 0.3753, test accuracy = 0.8361\n",
      "Epoch 867: train loss = 0.4268, test loss = 0.3748, test accuracy = 0.8361\n",
      "Epoch 868: train loss = 0.3973, test loss = 0.3743, test accuracy = 0.8361\n",
      "Epoch 869: train loss = 0.4010, test loss = 0.3734, test accuracy = 0.8525\n",
      "Epoch 870: train loss = 0.3841, test loss = 0.3727, test accuracy = 0.8525\n",
      "Epoch 871: train loss = 0.3873, test loss = 0.3721, test accuracy = 0.8525\n",
      "Epoch 872: train loss = 0.3752, test loss = 0.3717, test accuracy = 0.8525\n",
      "Epoch 873: train loss = 0.4030, test loss = 0.3716, test accuracy = 0.8525\n",
      "Epoch 874: train loss = 0.4139, test loss = 0.3715, test accuracy = 0.8525\n",
      "Epoch 875: train loss = 0.3845, test loss = 0.3713, test accuracy = 0.8525\n",
      "Epoch 876: train loss = 0.3605, test loss = 0.3712, test accuracy = 0.8525\n",
      "Epoch 877: train loss = 0.4147, test loss = 0.3712, test accuracy = 0.8525\n",
      "Epoch 878: train loss = 0.4064, test loss = 0.3715, test accuracy = 0.8525\n",
      "Epoch 879: train loss = 0.4056, test loss = 0.3718, test accuracy = 0.8525\n",
      "Epoch 880: train loss = 0.4160, test loss = 0.3722, test accuracy = 0.8525\n",
      "Epoch 881: train loss = 0.4249, test loss = 0.3725, test accuracy = 0.8525\n",
      "Epoch 882: train loss = 0.3787, test loss = 0.3728, test accuracy = 0.8525\n",
      "Epoch 883: train loss = 0.3619, test loss = 0.3730, test accuracy = 0.8525\n",
      "Epoch 884: train loss = 0.4062, test loss = 0.3733, test accuracy = 0.8525\n",
      "Epoch 885: train loss = 0.4174, test loss = 0.3732, test accuracy = 0.8525\n",
      "Epoch 886: train loss = 0.4150, test loss = 0.3730, test accuracy = 0.8525\n",
      "Epoch 887: train loss = 0.4246, test loss = 0.3727, test accuracy = 0.8525\n",
      "Epoch 888: train loss = 0.4251, test loss = 0.3726, test accuracy = 0.8525\n",
      "Epoch 889: train loss = 0.4080, test loss = 0.3728, test accuracy = 0.8525\n",
      "Epoch 890: train loss = 0.3969, test loss = 0.3730, test accuracy = 0.8525\n",
      "Epoch 891: train loss = 0.3697, test loss = 0.3730, test accuracy = 0.8525\n",
      "Epoch 892: train loss = 0.4225, test loss = 0.3728, test accuracy = 0.8525\n",
      "Epoch 893: train loss = 0.3885, test loss = 0.3724, test accuracy = 0.8525\n",
      "Epoch 894: train loss = 0.3642, test loss = 0.3724, test accuracy = 0.8525\n",
      "Epoch 895: train loss = 0.4119, test loss = 0.3721, test accuracy = 0.8525\n",
      "Epoch 896: train loss = 0.3822, test loss = 0.3718, test accuracy = 0.8525\n",
      "Epoch 897: train loss = 0.3801, test loss = 0.3714, test accuracy = 0.8525\n",
      "Epoch 898: train loss = 0.4390, test loss = 0.3709, test accuracy = 0.8525\n",
      "Epoch 899: train loss = 0.4152, test loss = 0.3703, test accuracy = 0.8525\n",
      "Epoch 900: train loss = 0.3647, test loss = 0.3700, test accuracy = 0.8525\n",
      "Epoch 901: train loss = 0.3659, test loss = 0.3698, test accuracy = 0.8525\n",
      "Epoch 902: train loss = 0.4029, test loss = 0.3694, test accuracy = 0.8525\n",
      "Epoch 903: train loss = 0.3733, test loss = 0.3693, test accuracy = 0.8525\n",
      "Epoch 904: train loss = 0.3640, test loss = 0.3693, test accuracy = 0.8525\n",
      "Epoch 905: train loss = 0.3979, test loss = 0.3696, test accuracy = 0.8525\n",
      "Epoch 906: train loss = 0.3400, test loss = 0.3701, test accuracy = 0.8525\n",
      "Epoch 907: train loss = 0.4242, test loss = 0.3706, test accuracy = 0.8525\n",
      "Epoch 908: train loss = 0.4354, test loss = 0.3710, test accuracy = 0.8525\n",
      "Epoch 909: train loss = 0.4269, test loss = 0.3716, test accuracy = 0.8525\n",
      "Epoch 910: train loss = 0.4138, test loss = 0.3720, test accuracy = 0.8689\n",
      "Epoch 911: train loss = 0.4074, test loss = 0.3719, test accuracy = 0.8689\n",
      "Epoch 912: train loss = 0.4053, test loss = 0.3720, test accuracy = 0.8689\n",
      "Epoch 913: train loss = 0.4739, test loss = 0.3720, test accuracy = 0.8689\n",
      "Epoch 914: train loss = 0.4099, test loss = 0.3718, test accuracy = 0.8689\n",
      "Epoch 915: train loss = 0.4267, test loss = 0.3715, test accuracy = 0.8689\n",
      "Epoch 916: train loss = 0.4645, test loss = 0.3714, test accuracy = 0.8689\n",
      "Epoch 917: train loss = 0.4181, test loss = 0.3712, test accuracy = 0.8525\n",
      "Epoch 918: train loss = 0.3888, test loss = 0.3706, test accuracy = 0.8525\n",
      "Epoch 919: train loss = 0.4287, test loss = 0.3701, test accuracy = 0.8525\n",
      "Epoch 920: train loss = 0.4023, test loss = 0.3696, test accuracy = 0.8525\n",
      "Epoch 921: train loss = 0.3697, test loss = 0.3693, test accuracy = 0.8525\n",
      "Epoch 922: train loss = 0.4090, test loss = 0.3691, test accuracy = 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923: train loss = 0.3567, test loss = 0.3690, test accuracy = 0.8525\n",
      "Epoch 924: train loss = 0.3922, test loss = 0.3688, test accuracy = 0.8525\n",
      "Epoch 925: train loss = 0.4042, test loss = 0.3688, test accuracy = 0.8525\n",
      "Epoch 926: train loss = 0.4014, test loss = 0.3688, test accuracy = 0.8525\n",
      "Epoch 927: train loss = 0.4136, test loss = 0.3690, test accuracy = 0.8525\n",
      "Epoch 928: train loss = 0.4203, test loss = 0.3693, test accuracy = 0.8525\n",
      "Epoch 929: train loss = 0.3737, test loss = 0.3694, test accuracy = 0.8525\n",
      "Epoch 930: train loss = 0.3756, test loss = 0.3694, test accuracy = 0.8525\n",
      "Epoch 931: train loss = 0.3896, test loss = 0.3697, test accuracy = 0.8525\n",
      "Epoch 932: train loss = 0.4059, test loss = 0.3700, test accuracy = 0.8525\n",
      "Epoch 933: train loss = 0.4090, test loss = 0.3703, test accuracy = 0.8525\n",
      "Epoch 934: train loss = 0.4453, test loss = 0.3706, test accuracy = 0.8525\n",
      "Epoch 935: train loss = 0.4370, test loss = 0.3707, test accuracy = 0.8525\n",
      "Epoch 936: train loss = 0.4038, test loss = 0.3705, test accuracy = 0.8525\n",
      "Epoch 937: train loss = 0.3778, test loss = 0.3702, test accuracy = 0.8525\n",
      "Epoch 938: train loss = 0.4425, test loss = 0.3699, test accuracy = 0.8525\n",
      "Epoch 939: train loss = 0.4089, test loss = 0.3700, test accuracy = 0.8525\n",
      "Epoch 940: train loss = 0.3889, test loss = 0.3703, test accuracy = 0.8525\n",
      "Epoch 941: train loss = 0.4159, test loss = 0.3706, test accuracy = 0.8525\n",
      "Epoch 942: train loss = 0.4308, test loss = 0.3708, test accuracy = 0.8525\n",
      "Epoch 943: train loss = 0.4249, test loss = 0.3707, test accuracy = 0.8525\n",
      "Epoch 944: train loss = 0.3942, test loss = 0.3704, test accuracy = 0.8525\n",
      "Epoch 945: train loss = 0.4054, test loss = 0.3700, test accuracy = 0.8525\n",
      "Epoch 946: train loss = 0.3983, test loss = 0.3697, test accuracy = 0.8525\n",
      "Epoch 947: train loss = 0.3854, test loss = 0.3696, test accuracy = 0.8525\n",
      "Epoch 948: train loss = 0.3911, test loss = 0.3697, test accuracy = 0.8525\n",
      "Epoch 949: train loss = 0.4115, test loss = 0.3694, test accuracy = 0.8525\n",
      "Epoch 950: train loss = 0.4068, test loss = 0.3693, test accuracy = 0.8525\n",
      "Epoch 951: train loss = 0.3884, test loss = 0.3692, test accuracy = 0.8525\n",
      "Epoch 952: train loss = 0.4220, test loss = 0.3696, test accuracy = 0.8525\n",
      "Epoch 953: train loss = 0.4118, test loss = 0.3699, test accuracy = 0.8525\n",
      "Epoch 954: train loss = 0.4526, test loss = 0.3703, test accuracy = 0.8525\n",
      "Epoch 955: train loss = 0.3696, test loss = 0.3706, test accuracy = 0.8525\n",
      "Epoch 956: train loss = 0.4243, test loss = 0.3708, test accuracy = 0.8525\n",
      "Epoch 957: train loss = 0.4262, test loss = 0.3712, test accuracy = 0.8525\n",
      "Epoch 958: train loss = 0.4207, test loss = 0.3714, test accuracy = 0.8525\n",
      "Epoch 959: train loss = 0.4013, test loss = 0.3716, test accuracy = 0.8525\n",
      "Epoch 960: train loss = 0.4059, test loss = 0.3715, test accuracy = 0.8525\n",
      "Epoch 961: train loss = 0.4038, test loss = 0.3712, test accuracy = 0.8525\n",
      "Epoch 962: train loss = 0.4125, test loss = 0.3707, test accuracy = 0.8525\n",
      "Epoch 963: train loss = 0.3965, test loss = 0.3701, test accuracy = 0.8525\n",
      "Epoch 964: train loss = 0.3928, test loss = 0.3697, test accuracy = 0.8525\n",
      "Epoch 965: train loss = 0.4418, test loss = 0.3691, test accuracy = 0.8525\n",
      "Epoch 966: train loss = 0.4016, test loss = 0.3684, test accuracy = 0.8525\n",
      "Epoch 967: train loss = 0.3783, test loss = 0.3680, test accuracy = 0.8525\n",
      "Epoch 968: train loss = 0.3936, test loss = 0.3677, test accuracy = 0.8525\n",
      "Epoch 969: train loss = 0.3673, test loss = 0.3676, test accuracy = 0.8525\n",
      "Epoch 970: train loss = 0.3985, test loss = 0.3678, test accuracy = 0.8525\n",
      "Epoch 971: train loss = 0.3636, test loss = 0.3682, test accuracy = 0.8525\n",
      "Epoch 972: train loss = 0.3879, test loss = 0.3685, test accuracy = 0.8525\n",
      "Epoch 973: train loss = 0.3976, test loss = 0.3688, test accuracy = 0.8525\n",
      "Epoch 974: train loss = 0.3950, test loss = 0.3688, test accuracy = 0.8525\n",
      "Epoch 975: train loss = 0.3598, test loss = 0.3690, test accuracy = 0.8525\n",
      "Epoch 976: train loss = 0.4456, test loss = 0.3693, test accuracy = 0.8525\n",
      "Epoch 977: train loss = 0.3813, test loss = 0.3696, test accuracy = 0.8525\n",
      "Epoch 978: train loss = 0.3706, test loss = 0.3699, test accuracy = 0.8525\n",
      "Epoch 979: train loss = 0.4185, test loss = 0.3704, test accuracy = 0.8689\n",
      "Epoch 980: train loss = 0.3837, test loss = 0.3707, test accuracy = 0.8689\n",
      "Epoch 981: train loss = 0.3926, test loss = 0.3710, test accuracy = 0.8689\n",
      "Epoch 982: train loss = 0.3568, test loss = 0.3713, test accuracy = 0.8689\n",
      "Epoch 983: train loss = 0.3990, test loss = 0.3713, test accuracy = 0.8689\n",
      "Epoch 984: train loss = 0.4032, test loss = 0.3708, test accuracy = 0.8689\n",
      "Epoch 985: train loss = 0.3595, test loss = 0.3697, test accuracy = 0.8689\n",
      "Epoch 986: train loss = 0.4093, test loss = 0.3691, test accuracy = 0.8525\n",
      "Epoch 987: train loss = 0.3677, test loss = 0.3687, test accuracy = 0.8525\n",
      "Epoch 988: train loss = 0.3692, test loss = 0.3686, test accuracy = 0.8525\n",
      "Epoch 989: train loss = 0.4161, test loss = 0.3686, test accuracy = 0.8525\n",
      "Epoch 990: train loss = 0.4196, test loss = 0.3683, test accuracy = 0.8525\n",
      "Epoch 991: train loss = 0.4079, test loss = 0.3679, test accuracy = 0.8525\n",
      "Epoch 992: train loss = 0.4261, test loss = 0.3677, test accuracy = 0.8525\n",
      "Epoch 993: train loss = 0.3727, test loss = 0.3674, test accuracy = 0.8525\n",
      "Epoch 994: train loss = 0.4308, test loss = 0.3670, test accuracy = 0.8525\n",
      "Epoch 995: train loss = 0.3910, test loss = 0.3667, test accuracy = 0.8525\n",
      "Epoch 996: train loss = 0.3652, test loss = 0.3664, test accuracy = 0.8525\n",
      "Epoch 997: train loss = 0.4214, test loss = 0.3661, test accuracy = 0.8525\n",
      "Epoch 998: train loss = 0.4428, test loss = 0.3661, test accuracy = 0.8525\n",
      "Epoch 999: train loss = 0.3954, test loss = 0.3660, test accuracy = 0.8525\n",
      "Epoch 1000: train loss = 0.3309, test loss = 0.3659, test accuracy = 0.8525\n",
      "Final test accuracy: 0.8525\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(1000):\n",
    "    train_loss = train(model, X_train, y_train, optimizer, loss_fn)\n",
    "    test_loss, test_accuracy = evaluate(model, X_test, y_test, loss_fn)\n",
    "    print(f'Epoch {epoch + 1}: train loss = {train_loss:.4f}, test loss = {test_loss:.4f}, test accuracy = {test_accuracy:.4f}')\n",
    "\n",
    "print(f'Final test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}